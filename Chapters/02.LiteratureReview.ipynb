{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Literature Review\n",
    "\n",
    "[index](../Index.ipynb) | [prev](./01.Introduction.ipynb) | [next](./03.SystemDesign.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter provides a theoretical foundation for the key ideas and algorithms, which can be found inside this research. \n",
    "\n",
    "**Note:**\n",
    "\n",
    "Code samples used to generate most of the plots can be found in the [Extra Notebook 1](../Notebooks/Extra.01.LiteratureReview.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Data Collection\n",
    "\n",
    "Data Collection involves a mini-computer (Raspberry Pi) which streams the data to the central unit (a Ubuntu-based Desktop PC with a GPU), which runs an infinite loop with the two key algorithms:\n",
    "- Backgroud subtraction\n",
    "- Yolo Object Recognition\n",
    "\n",
    "Both of these algorithms are extremelly useful in the image processing applications, and they represent a foundation of how data is collected in the system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1. Motion Detection\n",
    "\n",
    "Considering how objects of interest could be detected in a $30$ frames per second video stream, a naive approach would be to send all frames into an object detector.\n",
    "\n",
    "In theory this could work, but it would be extremely inefficient and resource intensive. Can a significant change in a series of images be detected first, and only then object detector utilised in the process?\n",
    "\n",
    "Here is an example of a static background:\n",
    "\n",
    "<p style=\"text-align: center; margin-bottom: 5px;\">Fig. 2.1</p>\n",
    "<img src=\"../Resources/img/no-motion.png\" style=\"width: 40%;\"/><br>\n",
    "\n",
    "And now a moving object (a person running) in a 7 consecutive frames:\n",
    "\n",
    "<p style=\"text-align: center; margin-bottom: 0;\">Fig. 2.2</p>\n",
    "<img src=\"../Resources/img/moving-object.png\" style=\"width: 90%;\"/>\n",
    "\n",
    "It turns out that there is already a set well established algorithms in the Computer Vision domain designed precisely for that purpose. They are not $100\\%$ bulletproof, but they do not need to be. If they can help to reject over $90\\%$ of static frames, GPU can be allocated to other tasks or simply kept idle to extend its lifespan. The bonus of not abusing GPU is a quiet machine and less heat generation.\n",
    "\n",
    "One of the most popular and successful methods for motion detection in images is the *Background Subtraction*.\n",
    "\n",
    "At a very high level the concept is very simple: there is a starting point with a static image without any moving objects (called *background* - $BG$). Then, every consecutive frame will be compared against the background to detect any changes in the *foreground* - $FG$.\n",
    "\n",
    "Unfortunately, there are many challenges in this optimistic approach:\n",
    "- the initial background might already contain moving objects\n",
    "- next frames actually don’t contain any moving objects, but only changes in light illumination\n",
    "- shadows appear and disappear\n",
    "- camera is in-door and light is turned on and off\n",
    "- tree branches move in the background\n",
    "- changing weather conditions (rain, snow, hail)\n",
    "- small objects constantly show in the camera lens\n",
    "\n",
    "These not so rare anomalies demand a more sophisticated approach than just a simple subtraction of foreground from the background.\n",
    "\n",
    "One very popular improvement over the vanilla algorithm has been proposed in the *Improved Adaptive Gaussian Mixture Model for Background Subtraction* paper (Zivkivoc 2004). The aim of Zivkivoc’s work was to overcome some of the challenges above and achieve efficiency by reducing the processing time.\n",
    "\n",
    "In the *MOG2* model, the background is constantly updated and not static. As author describes it, it uses recursive equations to constantly update parameters and also select appropriate number of components per each pixel. At a high level author describes a metric $R$ (using a Bayesian decision), which follows the formula:\n",
    "\n",
    "$$\n",
    "R=\\frac{p(BG|\\overrightarrow{x}^{(t)})}{p(FG|\\overrightarrow{x}^{(t)})}=\\frac{p(\\overrightarrow{x}^{(t)}|BG)p(BG)}{p(\\overrightarrow{x}^{(t)}|FG)p(FG)}\n",
    "$$\n",
    "\n",
    ", where the aim is to determine the ratio between the probability of new pixel at time $t$ being a foreground or a background.\n",
    "\n",
    "In general prior information about $FG$ is unknown, it is a uniform distribution. Then, a decision is made if object is a $BG$ if the probability of $x$ at time $t$, given $BG$ is greater than some threshold value ($c_{thr}$):\n",
    "\n",
    "$$\n",
    "p(\\overrightarrow{x}^{(t)}|BG) > (=Rc_{FG})\n",
    "$$\n",
    "\n",
    "The left side of the equation is referred to as a background model. It depends on the training set denoted as $X$.\n",
    "\n",
    "In order to eliminate the problem of suddenly changing lighting factor, authors proposed to keep updating the training set by dropping old values, appending new ones and re-estimating the background model (using Gaussian mixture model with $M$ components):\n",
    "\n",
    "$$\n",
    "\\hat{p}(\\overrightarrow{x}|X_T,BG+FG)=\\sum^{M}_{m=1}\\hat{\\pi}_m \\mathcal{N}(\\overrightarrow{x};\\hat{\\overrightarrow{\\mu}}_m,\\hat{\\sigma}^2_mI)\n",
    "$$\n",
    "\n",
    "Where means and variances, which describe the Gaussian components are added. Covariance matrices are\n",
    "diagonal and identity matrix has proper dimensions. The weights are non-negative and add up to 1.\n",
    "\n",
    "For each new data samples, equations are updated recursively, as follows:\n",
    "\n",
    "$$\n",
    "\\hat{\\pi}_m \\leftarrow \\hat{\\pi}_m + \\alpha(o^{(t)}_m-\\hat{\\pi}_m)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{\\overrightarrow{\\mu}}_m \\leftarrow \\hat{\\overrightarrow{\\mu}}_m + o^{(t)}_m (\\alpha/\\hat{\\pi}_m)\\overrightarrow{\\delta}_m\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{\\sigma}^2_m \\leftarrow \\hat{\\sigma}^2_m + o^{(t)}_m(\\alpha/\\hat{\\pi}_m)(\\overrightarrow{\\delta}^T_m \\overrightarrow{\\delta}_m  - \\hat{\\sigma}^2_m)\n",
    "$$\n",
    "\n",
    "There is an introduction of an $\\alpha$ - alpha parameter here, which is exponentially decaying, meaning that the older\n",
    "data samples will be given less importance:\n",
    "\n",
    "$$\n",
    "\\alpha=1/T\n",
    "$$\n",
    "\n",
    "In the new sample the $o_m^{(t)}$ value is set to $1$ for the component with a largest weight and $0$ in other\n",
    "components.\n",
    "\n",
    "The following formula denotes the squared distance from m-th component:\n",
    "\n",
    "$$\n",
    "\\overrightarrow{\\delta}_m^T \\overrightarrow{\\delta}_m / \\hat{\\sigma}^2_m\n",
    "$$\n",
    "\n",
    "If the maximum number of components is reached, the component with the lowest weight is removed. Hence\n",
    "the algorithm has been defined by the author to be an \"online clustering algorithm\".\n",
    "\n",
    "Author also describes how model deals with foreground objects, which remain static for a longer duration of\n",
    "time: for the FG object to be considered a BG, it needs to be static for approximately some number of frames:\n",
    "\n",
    "$$\n",
    "log(1-c_f)/log(1-\\alpha)\n",
    "$$\n",
    "\n",
    "$c_f$ stands for the maximum portion of data, which belongs to $FG$ objects without influencing the $BG$ model.\n",
    "For sample values for $c_f$ and $\\alpha$, author has calculated $105$ frames for the $FG$ object to be\n",
    "considered a $BG$.\n",
    "\n",
    "Weights define the underlying multinomial distribution. After additional derivations, author rewrites the first\n",
    "equation to the following form (this is after including the *Dirichlet* prior for multinomial distribution):\n",
    "\n",
    "$$\n",
    "\\hat{\\pi}_m \\leftarrow \\hat{\\pi}_m + \\alpha(o^{(t)}_m-\\hat{\\pi}_m) - \\alpha c_T\n",
    "$$\n",
    "\n",
    "Although the algorithm is very accurate, it has some trade offs and pre-requisites need to be met:\n",
    "- frame needs to be stationary\n",
    "- it is highly recommended to resize images (in theory, this is not a strong requirement, but this model is very slow when used with the 1080p or even 720p image resolution)\n",
    "\n",
    "The OpenCV implementation for Python can be found under `cv2.createBackgroundSubtractorMOG2` function, which I have used to detect motion between consecutive image frames.\n",
    "\n",
    "The parameters used for detection will be explained in the later Chapter: [Data Collection](./04.DataCollection.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2. Object Detection\n",
    "\n",
    "Once motion is detected, resized frames can be sent to an Object Detector to analyse the content of an image.\n",
    "\n",
    "Object detection comes from two fundamental ideas in Computer Vision:\n",
    "- Image Classification (look at an image and classify a single class: Car, Person, Dog etc.)\n",
    "- Object Localization (where an object is located inside an image)\n",
    "\n",
    "Object Detection's task is to classify multiple objects in an image and tell their locations.\n",
    "\n",
    "Here is an example screenshot from a web application, which I have built for this purpose. It detected motion and a single *Person* object in a real time camera stream:\n",
    "\n",
    "<p style=\"text-align: center; margin-bottom: 0;\">Fig. 2.3. Real time detection in Web App</p>\n",
    "<img src=\"../Resources/img/person-detected.png\" style=\"width: 50%;\"/>\n",
    "\n",
    "In *Fig. 2.3* there is a person walking by in front of the parking area. There is a purple rectangle around the person, called the *bounding box*. If there were more people in the frame, they would be contained in their own bounding boxes too.\n",
    "\n",
    "Object Detection is a dynamically evolving field with new algorithms and applications developed at high frequency. This is an advantage, as it creates new opportunities, but it is also a challenge for practicioners to keep up with the fast pace of change.\n",
    "\n",
    "Out of two arguably most popular options for object detection in Python: *Yolo* and *SSD*, I have decided to use Yolo (You Only Look Once) due to the fact that it can be run in real time on a GPU at $30+$ frames per second with good online documentation and wide-spread adoption rate. In comparison - I have not found a GPU implementation for the SSD (Single Shot Detector) algorithm and the amount of online knowledge about it is lacking.\n",
    "\n",
    "One could attribute Yolo's popularity to its catchy name, but it is nevetheless a very useful and fast algorithm for object detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Yolo V1:**\n",
    "\n",
    "Even though in my research I have used Yolo Version 2, the section below is dedicated to Yolo version 1, as it is the foundation for object detection, which utilises multiple Computer Vision and Deep Learning paradims.\n",
    "\n",
    "Yolo v1 (Redmon et al., 2015) has been released in 2015 as a new approach to object detection, which promised extreme speed and making real time object detection a reality. This was a significant achievement in comparison to previous object detectors, like R-CNN (Girshick et al. 2013) where a single image could take 20 seconds to get processed or even in comparison to more modern Fast R-CNN (Girshick 2015), which still took 2 seconds to process a single image and Faster R-CNN (Ren et al., 2015) with 0.14 second per frame.\n",
    "\n",
    "The processing time can be extremely important for certain applications, like self driving car or camera monitoring system. According to Yolo authors, algorithm can run at $45$ frames per second with a slight decrease in accuracy for smaller objects.\n",
    "\n",
    "To visualize progress in the area, I have put together a table below:\n",
    "\n",
    "| Detector      | FPS |\n",
    "| ------------- | --- |\n",
    "| R-CNN | 0.05 |\n",
    "| Fast R-CNN  | 0.5 |\n",
    "| Faster R-CNN | 7 |\n",
    "| Yolo v1 | 45 |\n",
    "\n",
    "Yolo owes the gain in speed to a complete re-think of how the object detectors can operate. Unlike a traditional approach, like sliding window with HOG (Histogram of Oriented Gradients), SVM (Support Vertor Machine) and region proposals (seen in R-CNN's), Yolo uses a single pass through the entire image to generate predictions (with the sliding window it might hav been event thousands passes through a single image of different size),\n",
    "\n",
    "Then, to get rid of overlapping bounding boxes, the ones with very low propability are discarded, and Non-max supression (Hosang et al., 2017) algorithm is applied.\n",
    "\n",
    "This approach generates an output of $1470$ feaures, containing all the data needed to understand the content of an image. Assuming $20$ object classes, the calculation is as follows:\n",
    "\n",
    "$$\n",
    "7x7x(2x5+20) = 7x7x30tensor = 1470features\n",
    "$$\n",
    "\n",
    ", where $7x7$ is related to a grid size, which image is divided by, $2x5$ stands for 2 bounding boxes inside each grid cell, and $20$ is a number of predicted classes in a One Hot Encoded notation.\n",
    "\n",
    "Each grid cell predicts two boxes and can only have a single class.\n",
    "\n",
    "Below is the name and description for each of the 5 nodes found in each bounding box:\n",
    "- $Conf$ - confidence\n",
    "- $x$ - x coordinate of center of the box (relative to grid cell)\n",
    "- $y$ - y coordinate\n",
    "- $w$ - width of the box (relative to whole image)\n",
    "- $h$ - height\n",
    "\n",
    "The confidence if object is present in the grid is calculated as:\n",
    "$Pr(Object)*IOU^{truth}_{pred}$\n",
    "\n",
    ", where $IOU$ represents an Intersection Over Union, an evaluation metric for bounding boxes:\n",
    "\n",
    "$$\n",
    "IOU=\\frac{areaOfOverlap}{areaOfUnion}\n",
    "$$\n",
    "\n",
    "If there is no object present in the cell, then the confidence will be zero, but if there is an object, it will equal to the $IOU$ metric.\n",
    "\n",
    "For training, a following Convolutional Neural network is used:\n",
    "\n",
    "<p style=\"text-align: center; margin-bottom: 0;\">Fig. 2.4. Yolo v1 architecture</p>\n",
    "<img src=\"../Resources/img/yolo-v1-architecture.png\" style=\"width: 75%;\"/>\n",
    "\n",
    ", with $24$ convolutional layers followed by $2$ fully connected layers. Convolutional layers are pretrained on ImageNet classification (with $1000$ classes), and final output is, as expected, a $7x7x30$ tensor.\n",
    "\n",
    "This type of complex network was trained for a week using the freely available *Darknet* framework, which is also used for the real time inference in this research.\n",
    "\n",
    "The network is trained with $224x224$ image resolution and then extended to $448x448$ at detection stage.\n",
    "\n",
    "As activation function, authors have used a leaky rectified linear activation (Leaky ReLU):\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "  f(x)=\\begin{cases}\n",
    "    x, & \\text{if $x>0$}\\\\\n",
    "    0.1x, & \\text{otherwise}\n",
    "  \\end{cases}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "The loss function to optimise is a highly customised $SumSquared Error$ with the specific characteristics:\n",
    "- to avoid issues with gradients for cells without any objects\n",
    "- to distinguish errors in large boxes versus small boxes (errors in large boxes matter less)\n",
    "\n",
    "Here are other significant training parameters:\n",
    "- epochs: $135$\n",
    "- batch size: $64$\n",
    "- momentum: $0.9$\n",
    "- decay: $0.0005$\n",
    "- custom learning rate schedule\n",
    "\n",
    "To prevent the overfit, dropout layers are introduced, and to increase image variability data augmentation is used.\n",
    "\n",
    "Overall, Yolo is a good tradeoff between speed and accuracy and at present is one of the most useful tools, which is free of cost and provides plethora of online documentation and examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Yolo V2:**\n",
    "\n",
    "An upgraded version of Yolo (V2) was released in 2016 as a state of the art real time object detector capable of detecting over $9000$ object categories.\n",
    "\n",
    "Capable of achieving a $76.8$ mAP (mean average precision) on VOC 2007 (The PASCAL Visual Object Classes Challenge 2007) while maintaining $40$ FPS (frames per second), which, as authors conclude, outperforms the other two most populate object detectors: *SSD* and *Faster RCNN with ResNet*.\n",
    "\n",
    "The main improvements in Yolo v2 have been achieved throgh a number of core ideas:\n",
    "- Batch Normalization: Added to all convolutional layers to stabilize training, speed up convergence and add regularisation\n",
    "- High Resolution Clasifier: End to end fully trained on $448x448$ image resolution, so more details can be detected\n",
    "- Convolutional With Anchor Boxes: Diving an image into N-overlapping boxes of WxH size - helpful to detect smaller objects, like multiple people faces\n",
    "- Dimension Clusters: Instead of hand picked anchor box dimensions, Yolo V2 uses k-means clustering with a custom distance metric $d(box,centroid)=1-IOU(box,centroid)$\n",
    "- Direct location prediction: Increase model stablity during early training iterations by introducing logistic activation to constrain network predictions or coordinates relative to the location of the cell grid\n",
    "- Multi-Scale Training: Aim is to make the model robust to varied image resolutions, which is achieved by randomly choosing a new image dimension every 10 batches during the training (size must be divisible by 32, from $320x320$ to $608x608$. When Yolo is run at $288x288$ it achieves much better performance, which might be useful for multiple video streams (for example one camera inside and two outside the house)\n",
    "\n",
    "The architecture is composed of $19$ convolutional layers and $5$ maxpolling layers. To process an image $5.58$ billion operations is required. This might seem very high, but it is much lower in comparison to a very popular choice for feature extractor VGG-16 (Simonyan et al. 2014), which require $30.69$ billion floating point operations. Yolo V1 required $8.52$ billion, as it was based on the Googlenet architecture (Shegedy et al. 2014).\n",
    "\n",
    "Yolo V2 uses its own classification model called *Darknet-19*, which is trained for classification and for detection using slightly different architecture and hyper-parameters from V1 and similar data augmentation techniques to V1.\n",
    "\n",
    "The *classification model* uses ImageNet dataset with $1000$ very fine-grained classes (like \"Norfolk terrier\") and *detection model* uses COCO dataset with $80$ high-level class names (like \"dog\").\n",
    "\n",
    "Since authors wanted to jointly train on classification and detection data, a *hierarchical classification* was used, where the final softmax layer with the flat encoding of mutually exclusive labels is not assumed. This has been achieved using an approach borrowed from Natural Language Processing called *WordTree*, where for each lower level class, a probability is calculated if this class belongs to a broader category, example:\n",
    "\n",
    "$$\n",
    "Pr(Norfolk-terrier|terrier)\n",
    "$$\n",
    "\n",
    "This model can been visualized as the following tree diagram:\n",
    "\n",
    "<p style=\"text-align: center; margin-bottom: 5px;\">Fig. 2.5. Yolo V2 WordTree</p>\n",
    "<img src=\"../Resources/img/word-tree.png\" style=\"width: 45%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Yolo V3, V4:**\n",
    "\n",
    "Since 2018 there have been already two iterations for Yolo object detector:\n",
    "- version 3 (Redmon et al. 2018)\n",
    "- version 4 (Bochkovskiy et al. 2020)\n",
    "\n",
    "They both look very promising in terms of further accuracy and performance boosts, but I am leaving this work for the future increments of this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3. Conclusion\n",
    "\n",
    "Yolo V2 represents a good trade off between accuracy and performance, and has proven to work well in case of detecting people and vehicles from the Raspberry Pi camera frames, which I discuss further in the [Data Collection](./04.DataCollection.ipynb) chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Forecasting\n",
    "\n",
    "<a id=\"fcst-begin\"></a>\n",
    "In advance of discussions about Machine Learning models, I would like to point out a fundamental concept: *Bias and Variance tradeoff*.\n",
    "\n",
    "We say that a model is good if it fits the training and testing data well. Models like Linear Regression create a straight line through the data points, and often do not represent the relationships very well. This is called *High Bias*. On the other hand, learners like Decision Trees model relationships in the training data very well, but tend to perform poorly on the testing sets. We call this behaviour *High Variance*. Ideally we always look for a model with relatively low bias and low variance. In practice, it is a matter of finding a good tradeoff.\n",
    "\n",
    "Although the above statement tends to hold for non-Neural Network models, it does not always apply to Neural Networks, which can generalise well, even with their complexity and High Variance (Neal et al., 2018).\n",
    "\n",
    "The Forecasting Chapter includes a study on a single *Naive* and three *Machine Learning* algorithms, which are compared next in the Literature Review:\n",
    "- Standard Decision Tree\n",
    "- Gradient Boosting Decision Tree\n",
    "- Gaussian Process\n",
    "\n",
    "As a side note, I have also explored many other algorithms, like:\n",
    "- Linear Regression\n",
    "- Random Forest\n",
    "- Multile variations of Feed Forward Neural Network\n",
    "- Long Short Term Memory Recurrent Neural Network (LSTM)\n",
    "\n",
    "Training so many Machine Learning models was a very valuable experience, but the additional algorithms listed above were not beneficial to the research results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1. Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Decision Trees* are a building block for many more sophisticated Machine Learning algorithms. Their simplicity and interpretability make them a very popular choice, when decisions must be clearly understood and explained.\n",
    "\n",
    "The history of Decision Trees used for regression problems is not very easy to track, and goes back to a research by J.N. Morgan (Morgan et al., 1963, p. 430) titled *Problems in the Analysis of Survey Data, and a Proposal*, where most likely first decision tree for regression was drawn. What has been a challenge back then (computational overhead) is actually not an issue in 2020, which makes Decision Trees one of the fastest Machine Learners available for relatively condensed datasets.\n",
    "\n",
    "The problem with decision trees is their low accuracy on an out-of-sample datasets and low robustness (small changes in training data may easily lead to a very different tree). It is however useful to discuss their inner workings before moving on to the more advanced algorithms.\n",
    "\n",
    "Here is an example output from a Tree Regressor algorithm run on a small subset of $100$ observations (for ilustrative purpose) from the dataset with *People* detections:\n",
    "\n",
    "<p style=\"text-align: center; margin-bottom: 5px;\">Fig. 2.6. Decision Tree</p>\n",
    "<img src=\"../Resources/img/tree.png\" style=\"width: 55%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tree can be interpreted as a series of sub-decisions to reach a decision goal. Following the *right hand side path*, the model predicts a value of $2.875$ by making the following decisions:\n",
    "- `uvIndex` is greater than $0.5$\n",
    "- `temperature` is greater than $2.99$\n",
    "- `hour` is greater than $10$\n",
    "\n",
    "It intuitively makes sense, as during the day, when temperature is not very low and after 10AM, expectation of approximately $3$ objects is correct.\n",
    "\n",
    "Below is the basic terminology related to the hierarchy above:\n",
    "- the single box on top of the diagram is called a *root node*\n",
    "- nodes in the middle are called the *decision nodes* and are connected by arrows creating a section called a *branch*\n",
    "- the eight boxes in the bottom are *leaf nodes*\n",
    "\n",
    "The best split for Regression Trees is usually calculated using *mean squared error*, however other metrics (like *mean absolute error*) can be utilised as well.\n",
    "\n",
    "The top-down procedure to generate a tree is the same for each node:\n",
    "- iterate through candidate features\n",
    "- for each feature:\n",
    "    - sort values\n",
    "    - find average between each pair of values and use as a candidate split value\n",
    "    - calculate average for values the left and right nodes\n",
    "    - calculate squared residuals for each node\n",
    "    - sum all residucals or average those\n",
    "- split the data by the feature and value, which produces the lowest squared error\n",
    "- keep doing this until:\n",
    "    - reached maximum depth of a tree allowed\n",
    "    - there is not enough samples to create a split\n",
    "    - all samples contain the same value\n",
    "- leaf nodes will eventually contain an average value for the target variable\n",
    "\n",
    "Hyperparameters `max_depth` and `min_samples_split` are used as a regularization term to avoid creating a model with *too high variance*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2. Gradient Boosting Regressor Tree\n",
    "\n",
    "There are many extensions to the base Decision Tree algorithm. I have found the Gradient Boosting Regressor to perform the best with the object detections dataset.\n",
    "\n",
    "The *Histogram Based Gradient Boosting Regressor* is a relatively new estimator added in 2019 into the Sci-Kit Learn library, developed in *Cython* to optimise speed. It is very efficient and capable of handling large datasets and missing values.\n",
    "\n",
    "The implementation in sklearn was inspired by the 2017 paper by Guolin Ke et al. (Ke et al., 2017), *LightGBM: A Highly Efficient Gradient Boosting Decision Tree* and it is a modern take on the original Gradient Boosting Machine algorithm by Jerome Friedman (Friedman, 1999).\n",
    "\n",
    "The original algorithm developed by Friedman puts robustness as one of the most favorable characteristics. The paper also mentions that the TreeBoost removes the need for feature transformations, and chooses only important features, while ignoring irrelevant input variables. It handles missing data, and enhances stabilty through the use of many small trees (instead of a single large one). Author admits that single Decision Tree is easier to interpret than many (even hundreds) small trees, however when one tree grows to a very large scale, this conclusion does not hold any more.\n",
    "\n",
    "Friedman's algorithm can be described in a sequence of steps:\n",
    "\n",
    "- Start with a dataset consisting of input features and a target variable $\\{(x_j, y_i)\\}^n_{i=1}$ and a Loss Function, which is *differentiable* $L(y,F(x))$ (like *least squares*)\n",
    "- Initialize a model with a constant value: $F_0(x)=argmin_{\\gamma} \\sum^n_{i=1}L(y_i,\\gamma)$, solve this equation find the initial predictions by taking the derivatives for the losses for each target, summing them up and setting the sum to $0$. In the Decision Tree terminology, this step creates a leaf, which predicts the initial values\n",
    "- Next section is an iteration for $m=1$ to $M$ which produces $M$ small trees (where $M$ is a hyperparameter to tune), and contains following steps\n",
    "    - Compute $r_{im} = -[\\frac{\\partial L(y_i,F(x_i))}{\\partial F(x_i)}]_{F(x}=F_{m-1}(x)$ for $i=1,...,n$\n",
    "    - Fit regression tree to the $r_{im}$ values and create terminal regions $R_{jm}$ for $j=1...J_m$\n",
    "    - For $j=1,...,J_m$ compute $\\gamma_{jm}=argmin_{\\gamma} \\sum_{x_i \\in R_{ij}} L(y_j,F_{m-1}(x_i)+\\gamma)$\n",
    "    - Update $F_m(x)=F_{m-1}(x)+\\nu \\sum^{J_m}_{j=1}\\gamma_m I(x \\in R_{jm})$, where $\\nu$ is another hyperparameter to tune, the learning rate\n",
    "- The iteration stops when either all steps were exhausted or when there is no significant change in the errors\n",
    "\n",
    "The key idea in the *Histogram Based Gradient Boosting* is related to the way Decision Trees find the best value to split the data. Where vanilla Gradient Boosting algorithm sorts the values and then for each pair of values runs a test if the split is optimal, histogram based Tree avoids the computational problem for larger datasets by binning the values into (typically) $256$ bins and use integer-based data structures (histograms). This way expensive sorting and testing all continous floating point values is avoided.\n",
    "\n",
    "One of the most recent improvements in this algorithm in `sklearn` is a *Poisson* loss function, which is more suitable when data is believed to come from a Poisson distribution (adequate for count data):\n",
    "\n",
    "$$\n",
    "L(y,\\hat{y})=\\frac{1}{N}\\sum^N_{i=0}(\\hat{y}_i-y_ilog\\hat{y}_i)\n",
    "$$\n",
    "\n",
    ", where $\\hat{y}$ is the predicted expected value and $y$ is the ground truth value.\n",
    "\n",
    "Poisson is a discrete probability distribution, which expresses the probability of a given number of events occurring in a fixed interval of time or space if these events occur with a known constant mean rate and independently of the time since the last event [wiki-link](https://en.wikipedia.org/wiki/Poisson_distribution)\n",
    "\n",
    "Probability mass function of $X$ for $k=0,1,2,3, ...$ is given by:\n",
    "\n",
    "$$f(k;\\lambda) = Pr(X=k) = \\frac{\\lambda^{k} e^{-\\lambda}}{k!})$$\n",
    "\n",
    ", where $\\lambda>0$, *expected value* and *variance* are both equal to $\\lambda$, e is Euler's number ($e=2.718...$) and $k!$ is the factorial of k.\n",
    "\n",
    "Minimising the Poisson loss is equivalent of maximizing the likelihood of the data under the assumption that the target comes from a Poisson distribution, conditioned on the input ([peltarion.com, Poisson loss](https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/poisson)).\n",
    "\n",
    "This feature is utilised in the [Forecasting Notebook](./05.Forecasting.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3. Gaussian Process\n",
    "\n",
    "Gaussian Distribution, also known as Normal Distribution is the cornerstone of statistical learning.\n",
    "\n",
    "Its origins go back to the theory with Abrhama de Moivre (1667-1754) and Carl Friedrich Gauss (1777-1855), and it is a fundamental concept used to model real-valued, random and continuous variables, which can be observed vastly in the nature, social studies, mathematics and engineering.\n",
    "\n",
    "The Central Limit Theorem (Laplace 1810) and unique analytical properties make Gaussian distributions a very useful tool, which can be also applied to Machine Learning.\n",
    "\n",
    "The literature review below takes a gradual approach in order to understand the Gaussian Processes ([peterroelants blog](https://peterroelants.github.io)):\n",
    "- Univariate Gaussian Distribution\n",
    "- Multivariate Gaussian Distribution\n",
    "- Gaussian Process\n",
    "\n",
    "It is interesting for this research as Gaussian Process can be used to make future predictions given the historical data, and it can also generate an uncertainty about these predictions, which allows for more informed decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Univariate Gaussian**\n",
    "\n",
    "Gaussian distribution is given by:$\\mathcal{N}(\\mu, \\sigma^2)$, where $\\mu$ is the expected value of a distribution, and $\\sigma$ corresponds to a standard deviation from $\\mu$. Sigma squared ($\\sigma^2$) is also known as a variance.\n",
    "\n",
    "The $pdf$ (probability density function) for a normal distribution is given by:\n",
    "\n",
    "$$\n",
    "p(x|\\mu,\\sigma)=\\frac{1}{\\sqrt{2\\pi \\sigma^2}}exp(-\\frac{(x-\\mu)^2}{2\\sigma^2})\n",
    "$$\n",
    "\n",
    "The word \"univariate\" relates to a single random variable ($x$) in the equation above. Several values for $\\mu$ and $\\sigma$ can be plotted to observe the familiar *bell curves*:\n",
    "\n",
    "<p style=\"text-align: center; margin-bottom: 0;\">Fig. 2.7. Univariate Gaussian</p>\n",
    "<img src=\"../Resources/img/gaussian-uni.png\" style=\"width: 50%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multivariate Gaussian**\n",
    "\n",
    "Multivariate normal distribution is used for analysis of mutliple random variables (for example $x_1$ and $x_2$). Similarly to the univariate case, it is defined by a two parameters:\n",
    "- mean vector $\\mu$\n",
    "- covariance matrix $\\Sigma$, which measures how correlated each pair of variables is\n",
    "\n",
    "The quation below describes a join probability for the multivariate normal with $d$ variables (i.e. the dimension of the dataset):\n",
    "\n",
    "$$\n",
    "p(x|\\mu,\\Sigma)=\\frac{1}{\\sqrt{(2\\pi)^2|\\Sigma|}}exp(-\\frac{1}{2}(x-\\mu)^T \\Sigma^{-1} (x-\\mu))\n",
    "$$\n",
    "\n",
    ", where $x$ is this time a vector of values (of size $d$), $\\Sigma$ is the symmetric and positive definite covariance matrix (of size $dxd$), and $|\\Sigma|$ is its determinant.\n",
    "\n",
    "As a shorthand, we use $\\mathcal{N}(\\mu, \\Sigma)$ to denote this distribution.\n",
    "\n",
    "Below are a two examples of multivariate Gaussian distribution:\n",
    "- first example shows 2 uncorrelated variables. Change in $x_1$ does not mean a change in $x_2$ ($0, 0$ diagonals in $\\Sigma$):\n",
    "\n",
    "$$\n",
    "\\mathcal{N}\\left(\\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}, \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}\\right)\n",
    "$$\n",
    "\n",
    "- second example shows 2 highly correlated variables. When $x_1$ increases, $x_2$ will increase also ($0.9, 0.9$ diagonals in $\\Sigma$):\n",
    "\n",
    "$$\n",
    "\\mathcal{N}\\left(\\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}, \\begin{bmatrix} 1 & 0.9 \\\\ 0.9 & 1 \\end{bmatrix}\\right)\n",
    "$$\n",
    "\n",
    "<p style=\"text-align: center; margin-bottom: 5px;\">Fig. 2.8. Bivariate Gaussian</p>\n",
    "<img src=\"../Resources/img/gaussian-multi.png\" style=\"width: 50%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling from a multivariate distribution can be done by sampling from the standard normal $X~\\mathcal{N}(0, I_d)$, where $\\mu=0$ and covariance is the identity matrix $I_d$.\n",
    "\n",
    "*Affine transformation* is applied to $X$, where $Y=LX+\\mu$ and covariance $\\Sigma_y=LL^T$ (we can ommit the $\\Sigma$ from the affine transform, as it is an identity matrix.\n",
    "\n",
    "The next step is to find $L$ and this is done using a technique called the *Cholesky decomposition* (Cholesky 1910), which allows for efficient numerical solutions.\n",
    "\n",
    "A pseudo-code below to sample from the Correlated examples is included in the Extra Notebook [here](../Notebooks/Extra01.LiteratureReview.ipynb#sample-corr):\n",
    "\n",
    "The conditional distribution for $x$ given $y$ is defined as $p(x|y)=\\mathcal{N}(\\mu_{x|y}, \\Sigma_{x|y})$, with:\n",
    "\n",
    "$$\n",
    "\\mu_{x|y}=\\mu_x+CB^{-1}(y-\\mu_y)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Sigma_{x|y}=A-CB^{-1}C^T=\\tilde{A}^{-1}\n",
    "$$\n",
    "\n",
    ", with the symbols explained below:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} x \\\\ y \\end{bmatrix} \\sim \\mathcal{N}\\left(\\begin{bmatrix} \\mu_x \\\\ \\mu_y \\end{bmatrix}, \\begin{bmatrix} A & C \\\\ C^T & B\\end{bmatrix}\\right) = \\mathcal{N}(\\mu, \\Sigma)\n",
    "$$\n",
    "\n",
    "Pseudo-code to find means and covariances is also included in the Extra Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gaussian Process**\n",
    "\n",
    "Gaussian process is a stochastic process ([Wikipedia, 2020](https://en.wikipedia.org/wiki/Gaussian_process)) involving random variables, represented by a multivariate normal distribution. It is a joint distribution over inifitely many random variables, and as such, it is a distribution over functions $f(x)$ with a continous domain.\n",
    "\n",
    "When used in Machine Learning context, kernel function, which measures similarity between points is used to predict values for unseen observations.\n",
    "\n",
    "A practical benefit from such an approach is that the result is not only a point estimate, but also a range of standard deviations $\\sigma$, which can be interpreted as an uncertainty.\n",
    "\n",
    "Difference between the multivariate Gaussian and Gaussian process is that Gaussian processes operate on $mu$ and $\\Sigma$ defined as a function, which removes the limitation of the finite number of jointly distributed Gaussians.\n",
    "\n",
    "Gaussian process is defined as:\n",
    "\n",
    "$$\n",
    "f(x) \\sim \\mathcal{GP}(m(x), k(x,x'))\n",
    "$$\n",
    "\n",
    ", where $m(x)$ is a mean function and $k(x,x')$ is a covariance function.\n",
    "\n",
    "In the Bayesian language, selecting the specification for the covariance function (called the kernel function), is setting a prior information. Kernel needs to be positive-definite to be a valid function.\n",
    "\n",
    "The most commonly seen kernel function is the *Exponential Quadratic* ($RBF$ kernel), which produces a smooth function (see figure 2.9. below), and this is in fact the function used in this research. It is given by:\n",
    "\n",
    "$$\n",
    "k(x_a, x_b)=exp(-\\frac{1}{2\\sigma^2}\\|x_a-x_b\\|^2)\n",
    "$$\n",
    "\n",
    "One can sample from prior using a finite number of points and this results in a marginal distibution that is Gaussian.\n",
    "\n",
    "<p style=\"text-align: center; margin-bottom: 0;\">Fig. 2.9. Sampling from RBF</p>\n",
    "<img src=\"../Resources/img/gp-sampling-rbf.png\" style=\"width: 50%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Gaussian Process for regression is a three step process:\n",
    "\n",
    "1. Define a prior kernel function\n",
    "2. Create a posterior distribution, given some data and likelihood function\n",
    "3. Generate predictions ($y$) for the input variables ($X$)\n",
    "\n",
    "To make predictions $y_2=f(X_2)$, one would draw samples from the posterior distribution $p(y_2|y_1,X_1,X_2)$:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} y_1 \\\\ y_2 \\end{bmatrix} \\sim \\mathcal{N}\\left(\\begin{bmatrix} \\mu_1 \\\\ \\mu_2 \\end{bmatrix}, \\begin{bmatrix} \\Sigma_{11} & \\Sigma_{12} \\\\ \\Sigma_{21} & \\Sigma_{22} \\end{bmatrix}\\right)\n",
    "$$\n",
    "\n",
    "and then use the conditional distribution:\n",
    "\n",
    "$$\n",
    "\\mu_{2|1}=(\\Sigma^{-1}_{11} \\Sigma_{12})^T y_1\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Sigma_{2|1}=\\Sigma_{22}-(\\Sigma^{-1}_{12} \\Sigma_{12})^T \\Sigma_{12}\n",
    "$$\n",
    "\n",
    "$y_2$ can be predicted by using mean $\\mu_{2|1}$.\n",
    "\n",
    "The visualization for predictions for a noiseless distribution shows that uncertainty (a salmon-color fill around the sine wave) in the points with data (black dots below) is minimal, but it grows in the sections without any data points:\n",
    "\n",
    "<p style=\"text-align: center; margin-bottom: 0;\">Fig. 2.10. Gaussian Process predictions and uncertainty</p>\n",
    "<img src=\"../Resources/img/gp.png\" style=\"width: 60%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4. Conclusion\n",
    "\n",
    "Gaussian processes are a very elegant, robust and informed approach to Machine Learning. One not only generates predictions for unseen data, but also the uncertainty. This can be a very useful tool in the decision making.\n",
    "\n",
    "However it is important to keep in mind that working with larger datasets can be a **challenge** due to $\\mathcal{O}(n^3)$ complexity. In my eyes, certainly Gaussian process algorithms were very slow to train (given that I have only used them with $< 4000$ records) and they have consumed a lot of memory (GPy was much more efficient than pymc3).\n",
    "\n",
    "There are tricks used to decrease the complexity to $\\mathcal{O}(n^2)$ and new frameworks continously work on the improvements (pymc3 library is currently switching backend to TensorFlow), but training Gaussian Process-based models can be a challenging and time consuming task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Autoencoders for Anomaly Detection\n",
    "\n",
    "The core idea of the system in my research is Anomaly Detection. It could very useful to alert home owners when something out of the ordrinary is happening around their property.\n",
    "\n",
    "Below is a Literature Review on **Autoencoders**, which are a very useful Neural Network models often used for anomaly detection in large datasets (like image or text data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoencoder is a type of a Neural Network used to learn to predict (reconstruct) its own inputs. Based on this aspect it is loosely classified as an unsupervised learning algorithm.\n",
    "\n",
    "There seems to be no definitive evidence of the origins for this Neural Network architecture, but it is described in detail in an online [DeepLearning book](http://www.deeplearningbook.org/contents/autoencoders.html) (Goodfellow-et-al-2016), where author dates the method back all the way to 80's, even though the terminology and use cases have changed drastically over the years.\n",
    "\n",
    "In the modern are, autoencoders are used to achieve several goals, like:\n",
    "- data compression (dimensionality reduction)\n",
    "- image de-noising\n",
    "- anomaly detection\n",
    "- machine translation\n",
    "\n",
    "While there are several variants of this type of Neural Network, at a high level it can be represented in a following diagram from [towardsdatascience 2017](https://towardsdatascience.com/applied-deep-learning-part-3-autoencoders-1c083af4d798) article:\n",
    "\n",
    "<p style=\"text-align: center; margin-bottom: 0;\">Fig. 2.11. Autoencoder diagram</p>\n",
    "<img src=\"../Resources/img/ae.png\" style=\"width: 50%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the Encoder part is $h=f(x)$, then the Decoder is $r=g(h)$.\n",
    "\n",
    "The main idea behind this design is to use a Feed-Forward Network to learn to copy the Input, but due to the size-constrained bottleneck layer in the middle, only the most salient characteristics of the data are learned (an autoencoder, which can learn to reproduce the inputs perfectly would not be very useful).\n",
    "\n",
    "The learning process is fairly standard and aims to minimize a loss function:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(x, g(f(x)))\n",
    "$$\n",
    "\n",
    ", where $\\mathcal{L}$ can be any differentiable function like *mean squared error*, penalising $g(f(x))$ from being dissimar from $x$.\n",
    "\n",
    "When MSE is used, autoencoder can be compared to PCA, but with a non-linear choice for functions $f$ and $g$, it becomes a more powerful non-linear generalization of PCA.\n",
    "\n",
    "There are tradeoffs to such a powerful model. As authors of the DeepLearning book conclude, when this model is given too much capacity, it fails to learn anything useful.\n",
    "\n",
    "Given this challenge, a whole family of autoencoder type of models have been developed, with *Variational Autoencoders* being the most popular one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Conclusion\n",
    "\n",
    "Autoencoders conclude the Literature Review in this research. The knowledge base in the area of object detection, forecasting and anomaly detection is vast with new research papers and articles landing every day, but I hope that the overview above sets the tone on what is to come in the next chapters.\n",
    "\n",
    "And the next Chapter focuses on the overall **System Design**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[index](../Index.ipynb) | [prev](./01.Introduction.ipynb) | [next](./03.SystemDesign.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
