{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. High Level System Design\n",
    "\n",
    "[index](../Index.ipynb) | [prev](./02.LiteratureReview.ipynb) | [next](./04.DataCollection.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall system can be described as a two high level components:\n",
    "- Real time frame processing used for object and anomaly detection\n",
    "- Batch processing used for forecasting and anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Real time frame processing\n",
    "\n",
    "<a id=\"fig3.1\"></a>\n",
    "<p style=\"text-align: center; margin-bottom: 0;\">Fig. 3.1. System Design - Real Time Processing</p>\n",
    "<img src=\"../Resources/img/system-diagram-1.png\" style=\"width: 65%;\"/>\n",
    "\n",
    "**Diagram description:**\n",
    "\n",
    "- First step is to generate frames from the Raspberry Pi camera (1)\n",
    "- Then frames (as numpy arrays) flow to a Desktop PC using high performance message queue - ZMQ (2). PC then:\n",
    "    - detects motion\n",
    "    - detects objects and their locations in an image\n",
    "    - sends every frame to connect clients (using web browsers) (5)\n",
    "    - saves images on an SSD Drive (4) for further analysis and batch processing\n",
    "- Client web browser application is served by NodeJS web server (box3)\n",
    "\n",
    "The data flow and the steps in data processing are described in more detail in the [next chapter - Data Collection](./04.DataCollection.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Batch processing\n",
    "\n",
    "<p style=\"text-align: center; margin-bottom: 0;\">Fig. 3.2. System Design - Batch Processing</p>\n",
    "<img src=\"../Resources/img/system-diagram-2.png\" style=\"width: 80%;\"/>\n",
    "\n",
    "**Diagram description:**\n",
    "\n",
    "- The starting point contains raw images collected on the hard drive (1)\n",
    "- Every night a scheduled task is executed, where images from the whole day are converted into tabular dataset (2)\n",
    "- Then in step 3, another scheduled task runs once every week and counts unique observations into hourly buckets and this dataset is used by two processes: \n",
    "    - Weekly forecast training (4) of probabilistic model, which predicts count of objects to show in a given hour, predictions are updated every hour (4.1)\n",
    "    - Weekly anomaly detection training script (6) which uses a probabilitic approach to set up hourly thresholds, above which new objects are treated as anomalies. This anomaly verification runs in real time (5.1)\n",
    "- Tabular dataset with images is used to train an autoencoder model capable of classifying frames as annomalous vs non-annomalous (6). The classification happens in real time (box 6.1)\n",
    "\n",
    "Details for each process are be covered in chapters [Forecasting](05.Forecasting.ipynb) and [Anomaly Detection](./06.AnomalyDetection.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Conclusion\n",
    "\n",
    "This chapter has covered system capabilities at a high level. Next Chapter - [Data Collection](04.DataCollection.ipynb) - dives into more detail detail of the figure 3.1. seen above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[index](../Index.ipynb) | [prev](./02.LiteratureReview.ipynb) | [next](./04.DataCollection.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
