{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly detection from raw images (all objects)\n",
    "\n",
    "This Notebook serves a purpose to identify anomalies based on the patterns encoded in the raw images.\n",
    "\n",
    "The current state of affairs in terms of using DL for anomaly detection is described well in [this paper](https://arxiv.org/abs/1901.03407)\n",
    "\n",
    "### General idea\n",
    "\n",
    "The general idea here is as follows: Can we use an unsupervised ML technique to train a model without giving it any labels to pick up the images, which are different from the majority of images?\n",
    "\n",
    "It turns out that AutoEncoders can do it and have been used in the industry for mainly 3 purposes:\n",
    "- compressing datasets\n",
    "- denosing images\n",
    "- anomaly detection\n",
    "\n",
    "My strategy to automatically find the anomalous images will follow these steps:\n",
    "- load raw images from the disk\n",
    "- preprocess images\n",
    "- split dataset into train and test sets\n",
    "- define autoencoder architecture\n",
    "- train autoencoder and analyse training results\n",
    "- use test set and see which results produce highest error\n",
    "- ability to find the error threshold based on the percentage of anomalies (if we know that number)\n",
    "\n",
    "### Challenges / experiments to perform:\n",
    "\n",
    "There are many questions about this experiment and many ways of trying it. Here are the main questions, which I will try to answer in my analysis:\n",
    "- should we split the datsets by class or perform one training for all classes and let algorithm find anomalies?\n",
    "- how many images do we need to be representative? (whole dataset is over 300K samples)?\n",
    "- what resolution should images be?\n",
    "- should other image preprocessing tricks be applied (thresholding for example)?\n",
    "- what is the impact of including only the area of interest and hiding the terrain outside of the parking slot?\n",
    "- if vanila autoencoder does not do a good job, can variational autoencoder do it better?\n",
    "\n",
    "Paper on AutoEncoders to review [here](https://arxiv.org/pdf/1606.08921.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF -> Using GPU ->  PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "# import ConfigImports Notebook to import and configure libs\n",
    "%run ../ConfigImports.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset and clean it up\n",
    "\n",
    "First, lets load a dataframe with all image dates and filenames from a previously stored parquet file.\n",
    "\n",
    "Then lets remove the outage dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_idx</th>\n",
       "      <th>label</th>\n",
       "      <th>confidence</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>filename</th>\n",
       "      <th>img_n_boxes</th>\n",
       "      <th>time_ms</th>\n",
       "      <th>date_time</th>\n",
       "      <th>week_day</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72846</td>\n",
       "      <td>car</td>\n",
       "      <td>0.523175</td>\n",
       "      <td>298</td>\n",
       "      <td>7</td>\n",
       "      <td>426</td>\n",
       "      <td>71</td>\n",
       "      <td>2019-09-09</td>\n",
       "      <td>07.02.40</td>\n",
       "      <td>07.02.40.270_34c99836_car-car-car.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>2019-09-09 07:02:40.270</td>\n",
       "      <td>Monday</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72847</td>\n",
       "      <td>person</td>\n",
       "      <td>0.759682</td>\n",
       "      <td>489</td>\n",
       "      <td>31</td>\n",
       "      <td>518</td>\n",
       "      <td>106</td>\n",
       "      <td>2019-09-09</td>\n",
       "      <td>12.02.42</td>\n",
       "      <td>12.02.42.921_ea6c9143_person-bicycle.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>921</td>\n",
       "      <td>2019-09-09 12:02:42.921</td>\n",
       "      <td>Monday</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   img_idx   label  confidence   x1  y1   x2   y2        date      time                                  filename  img_n_boxes time_ms               date_time week_day  is_weekend  month  hour  min\n",
       "0    72846     car    0.523175  298   7  426   71  2019-09-09  07.02.40     07.02.40.270_34c99836_car-car-car.jpg            1     270 2019-09-09 07:02:40.270   Monday       False      9     7    2\n",
       "1    72847  person    0.759682  489  31  518  106  2019-09-09  12.02.42  12.02.42.921_ea6c9143_person-bicycle.jpg            2     921 2019-09-09 12:02:42.921   Monday       False      9    12    2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('../Datasets/AllObjectDetections_2019-09-09_2020-03-02.parquet.gzip')\n",
    "df = df.drop(labels=['index'], axis=1)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(643471, 18)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FAULTY_DATES = ['2020-01-13', '2020-01-14', '2020-02-28']\n",
    "idx = df['date'].isin(FAULTY_DATES)\n",
    "df = df.loc[~idx]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define helper functions using Computer Vision techniques\n",
    "\n",
    "First of, we need a quick way of displaying images in the Notebook. This is handled by the `imshow` function below, which is flexible enough to handle 3 types of inputs to display an image:\n",
    "- image file path\n",
    "- image as numpy array\n",
    "- grayscale and color images\n",
    "\n",
    "Next, I have defined the `process_frame` function, which allows to perform following operations on an image using flags as function arguments:\n",
    "- convert to gray scale \n",
    "- apply Gaussian blur\n",
    "- apply thresholding\n",
    "- crop region of interest using polyfill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, width=12, height=6):\n",
    "    \"\"\"\n",
    "    Show image using matplotlib. Function takes a path or a \n",
    "    numpy image and renders it in RBG color-space\n",
    "    \"\"\"\n",
    "    if isinstance(img, str):\n",
    "        img = cv2.imread(img)\n",
    "    rcParams['figure.figsize'] = width, height\n",
    "    plt.axis('off')\n",
    "    print(img.shape)\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB));\n",
    "    plt.show()\n",
    "\n",
    "def process_frame(frame, dims, is_gray=True, is_blur=False, is_thresh=False, is_polyfill=False,\n",
    "                  poly_values=None, debug_poly=False):\n",
    "    \"\"\"\n",
    "    Preprocess frame for Machine Learning:    \n",
    "    - resize to desired size to improve performance and reduce noise\n",
    "    - change to gray scale to improve performance and remove color variances\n",
    "    - apply Gaussian blur to remove noise\n",
    "    - threshold to partition an image into foreground and background\n",
    "    - mask out an area of an image bases on a poly shape\n",
    "    \"\"\"\n",
    "    if frame is None or frame.shape[0] == 0:\n",
    "        raise ValueError('Error: issue with frame!')\n",
    "    frame = cv2.resize(frame, dims)\n",
    "    if is_gray:\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "    if is_blur:\n",
    "        frame = cv2.GaussianBlur(frame, (5, 5), 0)\n",
    "    if is_thresh:\n",
    "        _, frame = cv2.threshold(frame, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    if is_polyfill:\n",
    "        wh  = np.array([frame.shape[0], frame.shape[1]])\n",
    "        poly_shape = np.array([poly_values * wh]).astype(np.int32)\n",
    "        cv2.fillConvexPoly(frame, poly_shape, (0, 0, 0))\n",
    "        if debug_poly:\n",
    "            for points in poly_shape:\n",
    "                for i, p in enumerate(points):\n",
    "                    text_points = (p[0] + 2 if p[0] < wh[0] else p[0] - 18, p[1] + 24)\n",
    "                    frame = cv2.circle(frame, tuple(p), 3, (0,255,0), 3)\n",
    "                    cv2.putText(frame, str(i), text_points, cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                            0.7, (0,0,255), 2)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example frame processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Todo: show all possible image processing based on the same image (render as 2x2 plot-grid)\n",
    "72 / 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automated parameter test\n",
    "\n",
    "There is so many permutations of potential options to select here that it cna get overwheling very quickly.\n",
    "\n",
    "What I have decided to do is to define a list of all parameters I would like to test and use Pythons `itertools.product` function to create a cartesian product of all parameters, and then test them all in a single loop, which can run overnight without a need to manually re-run the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: *nsamples10000_res28_blurFalse_threshFalse_polyFalse*\n",
      "Time is: 2020-05-31 08:46:08.143371\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f019e97406264484939f1ccb27a3758a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 2.0 % of data, 10000 out of 643471 data points\n",
      "Data shape: (10000, 28, 28)\n",
      "Data size in RAM: 7.48 MB\n",
      "Data reshaped shape: (10000, 28, 28, 1)\n",
      "Train shape: (8000, 28, 28, 1), test shape: (2000, 28, 28, 1)\n",
      "Mse threshold: 0.030151297187432567\n",
      "Outliers found: 6\n",
      "*******************************\n",
      "Running model: *nsamples10000_res28_blurFalse_threshFalse_polyTrue*\n",
      "Time is: 2020-05-31 08:49:23.081301\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "464e9b03fdc84ba4afbc300f4b88845f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 2.0 % of data, 10000 out of 643471 data points\n",
      "Data shape: (10000, 28, 28)\n",
      "Data size in RAM: 7.48 MB\n",
      "Data reshaped shape: (10000, 28, 28, 1)\n",
      "Train shape: (8000, 28, 28, 1), test shape: (2000, 28, 28, 1)\n",
      "Mse threshold: 0.02641601513884939\n",
      "Outliers found: 6\n",
      "*******************************\n",
      "Running model: *nsamples10000_res28_blurFalse_threshTrue_polyFalse*\n",
      "Time is: 2020-05-31 08:52:35.226835\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd69fb8e9394bf1ac7b0b83e8bdf77f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 2.0 % of data, 10000 out of 643471 data points\n",
      "Data shape: (10000, 28, 28)\n",
      "Data size in RAM: 7.48 MB\n",
      "Data reshaped shape: (10000, 28, 28, 1)\n",
      "Train shape: (8000, 28, 28, 1), test shape: (2000, 28, 28, 1)\n",
      "Mse threshold: 0.12844278384745098\n",
      "Outliers found: 6\n",
      "*******************************\n",
      "Running model: *nsamples10000_res28_blurFalse_threshTrue_polyTrue*\n",
      "Time is: 2020-05-31 08:55:45.842360\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9a0f8635504a10a19ed6d2884b9f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 2.0 % of data, 10000 out of 643471 data points\n",
      "Data shape: (10000, 28, 28)\n",
      "Data size in RAM: 7.48 MB\n",
      "Data reshaped shape: (10000, 28, 28, 1)\n",
      "Train shape: (8000, 28, 28, 1), test shape: (2000, 28, 28, 1)\n",
      "Mse threshold: 0.11257517378032166\n",
      "Outliers found: 6\n",
      "*******************************\n",
      "Running model: *nsamples10000_res28_blurTrue_threshFalse_polyFalse*\n",
      "Time is: 2020-05-31 08:58:57.021529\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e923944ddf4ad981cd6dc28267ce1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 2.0 % of data, 10000 out of 643471 data points\n",
      "Data shape: (10000, 28, 28)\n",
      "Data size in RAM: 7.48 MB\n",
      "Data reshaped shape: (10000, 28, 28, 1)\n",
      "Train shape: (8000, 28, 28, 1), test shape: (2000, 28, 28, 1)\n",
      "Mse threshold: 0.0066356908311135995\n",
      "Outliers found: 6\n",
      "*******************************\n",
      "Running model: *nsamples10000_res28_blurTrue_threshFalse_polyTrue*\n",
      "Time is: 2020-05-31 09:02:07.526526\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea758a54af034bc0bd62a3ccfa409024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 2.0 % of data, 10000 out of 643471 data points\n",
      "Data shape: (10000, 28, 28)\n",
      "Data size in RAM: 7.48 MB\n",
      "Data reshaped shape: (10000, 28, 28, 1)\n",
      "Train shape: (8000, 28, 28, 1), test shape: (2000, 28, 28, 1)\n",
      "Mse threshold: 0.006196196097414931\n",
      "Outliers found: 6\n",
      "*******************************\n",
      "Running model: *nsamples10000_res28_blurTrue_threshTrue_polyFalse*\n",
      "Time is: 2020-05-31 09:05:18.694185\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "335a7368f88440a19091183acbcfb643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 2.0 % of data, 10000 out of 643471 data points\n",
      "Data shape: (10000, 28, 28)\n",
      "Data size in RAM: 7.48 MB\n",
      "Data reshaped shape: (10000, 28, 28, 1)\n",
      "Train shape: (8000, 28, 28, 1), test shape: (2000, 28, 28, 1)\n",
      "Mse threshold: 0.09182971655577414\n",
      "Outliers found: 6\n",
      "*******************************\n",
      "Running model: *nsamples10000_res28_blurTrue_threshTrue_polyTrue*\n",
      "Time is: 2020-05-31 09:08:30.387377\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a804ccd8374ab39d3a90fa63bf0ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 2.0 % of data, 10000 out of 643471 data points\n",
      "Data shape: (10000, 28, 28)\n",
      "Data size in RAM: 7.48 MB\n",
      "Data reshaped shape: (10000, 28, 28, 1)\n",
      "Train shape: (8000, 28, 28, 1), test shape: (2000, 28, 28, 1)\n",
      "Mse threshold: 0.08234064362198067\n",
      "Outliers found: 6\n",
      "*******************************\n",
      "Running model: *nsamples10000_res56_blurFalse_threshFalse_polyFalse*\n",
      "Time is: 2020-05-31 09:11:42.902396\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bfc9c15cbcd4a66884b8d7f52fc02d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 2.0 % of data, 10000 out of 643471 data points\n",
      "Data shape: (10000, 56, 56)\n",
      "Data size in RAM: 29.91 MB\n",
      "Data reshaped shape: (10000, 56, 56, 1)\n",
      "Train shape: (8000, 56, 56, 1), test shape: (2000, 56, 56, 1)\n",
      "Mse threshold: 0.03275439545139667\n",
      "Outliers found: 6\n",
      "*******************************\n",
      "Running model: *nsamples10000_res56_blurFalse_threshFalse_polyTrue*\n",
      "Time is: 2020-05-31 09:15:10.788513\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d7211abccfb431696e812569a0e9017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 2.0 % of data, 10000 out of 643471 data points\n",
      "Data shape: (10000, 56, 56)\n",
      "Data size in RAM: 29.91 MB\n",
      "Data reshaped shape: (10000, 56, 56, 1)\n",
      "Train shape: (8000, 56, 56, 1), test shape: (2000, 56, 56, 1)\n",
      "Mse threshold: 0.028697996666654887\n",
      "Outliers found: 6\n",
      "*******************************\n",
      "Running model: *nsamples10000_res56_blurFalse_threshTrue_polyFalse*\n",
      "Time is: 2020-05-31 09:18:33.345452\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0234c2e9c98456ea2f09eb640b8c4e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception, will use previous image instead. Error: issue with frame! /data/security_cam_detections_v2/Front-Parking/2020-02-08/23.33.41.278_955bc21c_person.jpg\n",
      "\n",
      "Sampled 2.0 % of data, 10000 out of 643471 data points\n",
      "Data shape: (10000, 56, 56)\n",
      "Data size in RAM: 29.91 MB\n",
      "Data reshaped shape: (10000, 56, 56, 1)\n",
      "Train shape: (8000, 56, 56, 1), test shape: (2000, 56, 56, 1)\n",
      "Mse threshold: 0.12242201250046483\n",
      "Outliers found: 6\n",
      "*******************************\n",
      "Running model: *nsamples10000_res56_blurFalse_threshTrue_polyTrue*\n",
      "Time is: 2020-05-31 09:21:56.575836\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c690ca703d4c3bae4989f8fec20028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 2.0 % of data, 10000 out of 643471 data points\n",
      "Data shape: (10000, 56, 56)\n",
      "Data size in RAM: 29.91 MB\n",
      "Data reshaped shape: (10000, 56, 56, 1)\n",
      "Train shape: (8000, 56, 56, 1), test shape: (2000, 56, 56, 1)\n",
      "Mse threshold: 0.09791737712919707\n",
      "Outliers found: 6\n",
      "*******************************\n",
      "Running model: *nsamples10000_res56_blurTrue_threshFalse_polyFalse*\n",
      "Time is: 2020-05-31 09:25:41.799927\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b397805059445a983fd0955bb4ebe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 2.0 % of data, 10000 out of 643471 data points\n",
      "Data shape: (10000, 56, 56)\n",
      "Data size in RAM: 29.91 MB\n",
      "Data reshaped shape: (10000, 56, 56, 1)\n",
      "Train shape: (8000, 56, 56, 1), test shape: (2000, 56, 56, 1)\n",
      "Mse threshold: 0.012739982211962339\n",
      "Outliers found: 6\n",
      "*******************************\n",
      "Running model: *nsamples10000_res56_blurTrue_threshFalse_polyTrue*\n",
      "Time is: 2020-05-31 09:29:23.179365\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9117304c04534f56af9bc7adcfa59fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception, will use previous image instead. Error: issue with frame! /data/security_cam_detections_v2/Front-Parking/2020-01-25/23.32.10.480_afdcd96f_car.jpg\n",
      "\n",
      "Sampled 2.0 % of data, 10000 out of 643471 data points\n",
      "Data shape: (10000, 56, 56)\n",
      "Data size in RAM: 29.91 MB\n",
      "Data reshaped shape: (10000, 56, 56, 1)\n",
      "Train shape: (8000, 56, 56, 1), test shape: (2000, 56, 56, 1)\n",
      "Mse threshold: 0.012064086535014156\n",
      "Outliers found: 6\n",
      "*******************************\n",
      "Running model: *nsamples10000_res56_blurTrue_threshTrue_polyFalse*\n",
      "Time is: 2020-05-31 09:33:06.865564\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f2957f1a8545ffba77c41f382a5fa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 2.0 % of data, 10000 out of 643471 data points\n",
      "Data shape: (10000, 56, 56)\n",
      "Data size in RAM: 29.91 MB\n",
      "Data reshaped shape: (10000, 56, 56, 1)\n",
      "Train shape: (8000, 56, 56, 1), test shape: (2000, 56, 56, 1)\n",
      "Mse threshold: 0.1023946270942687\n",
      "Outliers found: 6\n",
      "*******************************\n",
      "Running model: *nsamples10000_res56_blurTrue_threshTrue_polyTrue*\n",
      "Time is: 2020-05-31 09:36:51.386676\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8072119bfc2c45488dbce6171b47ddf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 2.0 % of data, 10000 out of 643471 data points\n",
      "Data shape: (10000, 56, 56)\n",
      "Data size in RAM: 29.91 MB\n",
      "Data reshaped shape: (10000, 56, 56, 1)\n",
      "Train shape: (8000, 56, 56, 1), test shape: (2000, 56, 56, 1)\n",
      "Mse threshold: 0.08426738838106385\n",
      "Outliers found: 6\n",
      "*******************************\n",
      "Running model: *nsamples10000_res112_blurFalse_threshFalse_polyFalse*\n",
      "Time is: 2020-05-31 09:40:35.603504\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74694140e50349a2afb00a5cbeba84e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 2.0 % of data, 10000 out of 643471 data points\n",
      "Data shape: (10000, 112, 112)\n",
      "Data size in RAM: 119.63 MB\n",
      "Data reshaped shape: (10000, 112, 112, 1)\n",
      "Train shape: (8000, 112, 112, 1), test shape: (2000, 112, 112, 1)\n",
      "Mse threshold: 0.028746331680566048\n",
      "Outliers found: 6\n",
      "*******************************\n",
      "Running model: *nsamples10000_res112_blurFalse_threshFalse_polyTrue*\n",
      "Time is: 2020-05-31 09:46:54.107277\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6442844ae774e3297b58036d01578a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 2.0 % of data, 10000 out of 643471 data points\n",
      "Data shape: (10000, 112, 112)\n",
      "Data size in RAM: 119.63 MB\n",
      "Data reshaped shape: (10000, 112, 112, 1)\n",
      "Train shape: (8000, 112, 112, 1), test shape: (2000, 112, 112, 1)\n",
      "Mse threshold: 0.023956486996263165\n",
      "Outliers found: 6\n",
      "*******************************\n",
      "Running model: *nsamples10000_res112_blurFalse_threshTrue_polyFalse*\n",
      "Time is: 2020-05-31 09:53:12.969590\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3091e90e8d4149aea4ce3b5d46db5c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 2.0 % of data, 10000 out of 643471 data points\n",
      "Data shape: (10000, 112, 112)\n",
      "Data size in RAM: 119.63 MB\n",
      "Data reshaped shape: (10000, 112, 112, 1)\n",
      "Train shape: (8000, 112, 112, 1), test shape: (2000, 112, 112, 1)\n",
      "Mse threshold: 0.1080172287300227\n",
      "Outliers found: 6\n",
      "*******************************\n",
      "Running model: *nsamples10000_res112_blurFalse_threshTrue_polyTrue*\n",
      "Time is: 2020-05-31 09:59:32.021380\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4b68d3a8ab6415a855cda2bd57fb288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 2.0 % of data, 10000 out of 643471 data points\n",
      "Data shape: (10000, 112, 112)\n",
      "Data size in RAM: 119.63 MB\n",
      "Data reshaped shape: (10000, 112, 112, 1)\n",
      "Train shape: (8000, 112, 112, 1), test shape: (2000, 112, 112, 1)\n",
      "Mse threshold: 0.10136733427643772\n",
      "Outliers found: 6\n",
      "*******************************\n",
      "Running model: *nsamples10000_res112_blurTrue_threshFalse_polyFalse*\n",
      "Time is: 2020-05-31 10:05:51.572274\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11d379e3c0f74f888047fe590fb38a64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 2.0 % of data, 10000 out of 643471 data points\n",
      "Data shape: (10000, 112, 112)\n",
      "Data size in RAM: 119.63 MB\n",
      "Data reshaped shape: (10000, 112, 112, 1)\n",
      "Train shape: (8000, 112, 112, 1), test shape: (2000, 112, 112, 1)\n",
      "Mse threshold: 0.016775282131507942\n",
      "Outliers found: 6\n",
      "*******************************\n",
      "Running model: *nsamples10000_res112_blurTrue_threshFalse_polyTrue*\n",
      "Time is: 2020-05-31 10:12:11.744040\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92b931f660fe47b58a183b7eb927b578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 2.0 % of data, 10000 out of 643471 data points\n",
      "Data shape: (10000, 112, 112)\n",
      "Data size in RAM: 119.63 MB\n",
      "Data reshaped shape: (10000, 112, 112, 1)\n",
      "Train shape: (8000, 112, 112, 1), test shape: (2000, 112, 112, 1)\n",
      "Mse threshold: 0.0167347288560122\n",
      "Outliers found: 6\n",
      "*******************************\n",
      "Running model: *nsamples10000_res112_blurTrue_threshTrue_polyFalse*\n",
      "Time is: 2020-05-31 10:18:31.789920\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e51bc6b3fe8c4b2089b3398eba35061f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 2.0 % of data, 10000 out of 643471 data points\n",
      "Data shape: (10000, 112, 112)\n",
      "Data size in RAM: 119.63 MB\n",
      "Data reshaped shape: (10000, 112, 112, 1)\n",
      "Train shape: (8000, 112, 112, 1), test shape: (2000, 112, 112, 1)\n",
      "Mse threshold: 0.11818515797704447\n",
      "Outliers found: 6\n",
      "*******************************\n",
      "Running model: *nsamples10000_res112_blurTrue_threshTrue_polyTrue*\n",
      "Time is: 2020-05-31 10:24:52.436819\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a363ff0f184ba88e61522dfc53941d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 2.0 % of data, 10000 out of 643471 data points\n",
      "Data shape: (10000, 112, 112)\n",
      "Data size in RAM: 119.63 MB\n",
      "Data reshaped shape: (10000, 112, 112, 1)\n",
      "Train shape: (8000, 112, 112, 1), test shape: (2000, 112, 112, 1)\n",
      "Mse threshold: 0.08583414074033478\n",
      "Outliers found: 6\n",
      "*******************************\n",
      "Running model: *nsamples25000_res28_blurFalse_threshFalse_polyFalse*\n",
      "Time is: 2020-05-31 10:31:12.906143\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e608d7546274c2d969b5ccee7a0eb41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 4.0 % of data, 25000 out of 643471 data points\n",
      "Data shape: (25000, 28, 28)\n",
      "Data size in RAM: 18.69 MB\n",
      "Data reshaped shape: (25000, 28, 28, 1)\n",
      "Train shape: (20000, 28, 28, 1), test shape: (5000, 28, 28, 1)\n",
      "Mse threshold: 0.026877195367589472\n",
      "Outliers found: 15\n",
      "*******************************\n",
      "Running model: *nsamples25000_res28_blurFalse_threshFalse_polyTrue*\n",
      "Time is: 2020-05-31 10:39:30.119804\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba79c9d78f1a42bcbe67149942952d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 4.0 % of data, 25000 out of 643471 data points\n",
      "Data shape: (25000, 28, 28)\n",
      "Data size in RAM: 18.69 MB\n",
      "Data reshaped shape: (25000, 28, 28, 1)\n",
      "Train shape: (20000, 28, 28, 1), test shape: (5000, 28, 28, 1)\n",
      "Mse threshold: 0.024165811579674304\n",
      "Outliers found: 15\n",
      "*******************************\n",
      "Running model: *nsamples25000_res28_blurFalse_threshTrue_polyFalse*\n",
      "Time is: 2020-05-31 10:47:49.438767\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9042e8ce37a742bc8287c0b4399318b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 4.0 % of data, 25000 out of 643471 data points\n",
      "Data shape: (25000, 28, 28)\n",
      "Data size in RAM: 18.69 MB\n",
      "Data reshaped shape: (25000, 28, 28, 1)\n",
      "Train shape: (20000, 28, 28, 1), test shape: (5000, 28, 28, 1)\n",
      "Mse threshold: 0.11095449588447794\n",
      "Outliers found: 15\n",
      "*******************************\n",
      "Running model: *nsamples25000_res28_blurFalse_threshTrue_polyTrue*\n",
      "Time is: 2020-05-31 10:56:11.652770\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9483adaf0784f31975c9eb65e2fffbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception, will use previous image instead. Error: issue with frame! /data/security_cam_detections_v2/Front-Parking/2020-01-25/23.32.10.990_4c062cda_car.jpg\n",
      "\n",
      "Sampled 4.0 % of data, 25000 out of 643471 data points\n",
      "Data shape: (25000, 28, 28)\n",
      "Data size in RAM: 18.69 MB\n",
      "Data reshaped shape: (25000, 28, 28, 1)\n",
      "Train shape: (20000, 28, 28, 1), test shape: (5000, 28, 28, 1)\n",
      "Mse threshold: 0.08937916464358543\n",
      "Outliers found: 15\n",
      "*******************************\n",
      "Running model: *nsamples25000_res28_blurTrue_threshFalse_polyFalse*\n",
      "Time is: 2020-05-31 11:04:35.832475\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a8d179a7b841b5b39f9ea42d0c1c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 4.0 % of data, 25000 out of 643471 data points\n",
      "Data shape: (25000, 28, 28)\n",
      "Data size in RAM: 18.69 MB\n",
      "Data reshaped shape: (25000, 28, 28, 1)\n",
      "Train shape: (20000, 28, 28, 1), test shape: (5000, 28, 28, 1)\n",
      "Mse threshold: 0.00612341901380566\n",
      "Outliers found: 15\n",
      "*******************************\n",
      "Running model: *nsamples25000_res28_blurTrue_threshFalse_polyTrue*\n",
      "Time is: 2020-05-31 11:12:24.178298\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19da20402f52443e859aca2cc67541f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 4.0 % of data, 25000 out of 643471 data points\n",
      "Data shape: (25000, 28, 28)\n",
      "Data size in RAM: 18.69 MB\n",
      "Data reshaped shape: (25000, 28, 28, 1)\n",
      "Train shape: (20000, 28, 28, 1), test shape: (5000, 28, 28, 1)\n",
      "Mse threshold: 0.004626421972643579\n",
      "Outliers found: 15\n",
      "*******************************\n",
      "Running model: *nsamples25000_res28_blurTrue_threshTrue_polyFalse*\n",
      "Time is: 2020-05-31 11:20:20.818446\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58553b708d594d95a2956cdc9722e451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 4.0 % of data, 25000 out of 643471 data points\n",
      "Data shape: (25000, 28, 28)\n",
      "Data size in RAM: 18.69 MB\n",
      "Data reshaped shape: (25000, 28, 28, 1)\n",
      "Train shape: (20000, 28, 28, 1), test shape: (5000, 28, 28, 1)\n",
      "Mse threshold: 0.08949109727889239\n",
      "Outliers found: 15\n",
      "*******************************\n",
      "Running model: *nsamples25000_res28_blurTrue_threshTrue_polyTrue*\n",
      "Time is: 2020-05-31 11:28:16.925692\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c97326c926a04e74b467598aaa2864b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 4.0 % of data, 25000 out of 643471 data points\n",
      "Data shape: (25000, 28, 28)\n",
      "Data size in RAM: 18.69 MB\n",
      "Data reshaped shape: (25000, 28, 28, 1)\n",
      "Train shape: (20000, 28, 28, 1), test shape: (5000, 28, 28, 1)\n",
      "Mse threshold: 0.07008396092802263\n",
      "Outliers found: 15\n",
      "*******************************\n",
      "Running model: *nsamples25000_res56_blurFalse_threshFalse_polyFalse*\n",
      "Time is: 2020-05-31 11:36:10.815416\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50d16aecac824e339ccd1cdd205a1bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 4.0 % of data, 25000 out of 643471 data points\n",
      "Data shape: (25000, 56, 56)\n",
      "Data size in RAM: 74.77 MB\n",
      "Data reshaped shape: (25000, 56, 56, 1)\n",
      "Train shape: (20000, 56, 56, 1), test shape: (5000, 56, 56, 1)\n",
      "Mse threshold: 0.027343688230961536\n",
      "Outliers found: 15\n",
      "*******************************\n",
      "Running model: *nsamples25000_res56_blurFalse_threshFalse_polyTrue*\n",
      "Time is: 2020-05-31 11:45:11.219424\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dbd9c7c05904e5e842a0ed903ee0f02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 4.0 % of data, 25000 out of 643471 data points\n",
      "Data shape: (25000, 56, 56)\n",
      "Data size in RAM: 74.77 MB\n",
      "Data reshaped shape: (25000, 56, 56, 1)\n",
      "Train shape: (20000, 56, 56, 1), test shape: (5000, 56, 56, 1)\n",
      "Mse threshold: 0.024945608850568454\n",
      "Outliers found: 15\n",
      "*******************************\n",
      "Running model: *nsamples25000_res56_blurFalse_threshTrue_polyFalse*\n",
      "Time is: 2020-05-31 11:54:10.912374\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6923b84acfd64fa48339405c79d02de1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 4.0 % of data, 25000 out of 643471 data points\n",
      "Data shape: (25000, 56, 56)\n",
      "Data size in RAM: 74.77 MB\n",
      "Data reshaped shape: (25000, 56, 56, 1)\n",
      "Train shape: (20000, 56, 56, 1), test shape: (5000, 56, 56, 1)\n",
      "Mse threshold: 0.10350213849544519\n",
      "Outliers found: 15\n",
      "*******************************\n",
      "Running model: *nsamples25000_res56_blurFalse_threshTrue_polyTrue*\n",
      "Time is: 2020-05-31 12:03:11.304032\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b268da1ed85e4a7d88128ab07d2ac0e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 4.0 % of data, 25000 out of 643471 data points\n",
      "Data shape: (25000, 56, 56)\n",
      "Data size in RAM: 74.77 MB\n",
      "Data reshaped shape: (25000, 56, 56, 1)\n",
      "Train shape: (20000, 56, 56, 1), test shape: (5000, 56, 56, 1)\n",
      "Mse threshold: 0.0929753070026632\n",
      "Outliers found: 15\n",
      "*******************************\n",
      "Running model: *nsamples25000_res56_blurTrue_threshFalse_polyFalse*\n",
      "Time is: 2020-05-31 12:12:06.343658\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "786b26e169c14f868d7375c015e98e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 4.0 % of data, 25000 out of 643471 data points\n",
      "Data shape: (25000, 56, 56)\n",
      "Data size in RAM: 74.77 MB\n",
      "Data reshaped shape: (25000, 56, 56, 1)\n",
      "Train shape: (20000, 56, 56, 1), test shape: (5000, 56, 56, 1)\n",
      "Mse threshold: 0.011171493042260373\n",
      "Outliers found: 15\n",
      "*******************************\n",
      "Running model: *nsamples25000_res56_blurTrue_threshFalse_polyTrue*\n",
      "Time is: 2020-05-31 12:20:55.917881\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5099e6fca8c46168f5e52e76fa88eca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 4.0 % of data, 25000 out of 643471 data points\n",
      "Data shape: (25000, 56, 56)\n",
      "Data size in RAM: 74.77 MB\n",
      "Data reshaped shape: (25000, 56, 56, 1)\n",
      "Train shape: (20000, 56, 56, 1), test shape: (5000, 56, 56, 1)\n",
      "Mse threshold: 0.00866927228122946\n",
      "Outliers found: 15\n",
      "*******************************\n",
      "Running model: *nsamples25000_res56_blurTrue_threshTrue_polyFalse*\n",
      "Time is: 2020-05-31 12:29:25.472997\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dff57def5c914c518afcdf99dfcd158f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 4.0 % of data, 25000 out of 643471 data points\n",
      "Data shape: (25000, 56, 56)\n",
      "Data size in RAM: 74.77 MB\n",
      "Data reshaped shape: (25000, 56, 56, 1)\n",
      "Train shape: (20000, 56, 56, 1), test shape: (5000, 56, 56, 1)\n",
      "Mse threshold: 0.09949837638437742\n",
      "Outliers found: 15\n",
      "*******************************\n",
      "Running model: *nsamples25000_res56_blurTrue_threshTrue_polyTrue*\n",
      "Time is: 2020-05-31 12:38:18.557580\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0af807bd7b741dba5af7a9739603d5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 4.0 % of data, 25000 out of 643471 data points\n",
      "Data shape: (25000, 56, 56)\n",
      "Data size in RAM: 74.77 MB\n",
      "Data reshaped shape: (25000, 56, 56, 1)\n",
      "Train shape: (20000, 56, 56, 1), test shape: (5000, 56, 56, 1)\n",
      "Mse threshold: 0.08359585653245398\n",
      "Outliers found: 15\n",
      "*******************************\n",
      "Running model: *nsamples25000_res112_blurFalse_threshFalse_polyFalse*\n",
      "Time is: 2020-05-31 12:46:59.911893\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fa59376543d438c9967f6497c7a4e78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 4.0 % of data, 25000 out of 643471 data points\n",
      "Data shape: (25000, 112, 112)\n",
      "Data size in RAM: 299.07 MB\n",
      "Data reshaped shape: (25000, 112, 112, 1)\n",
      "Train shape: (20000, 112, 112, 1), test shape: (5000, 112, 112, 1)\n",
      "Mse threshold: 0.026399997495114763\n",
      "Outliers found: 15\n",
      "*******************************\n",
      "Running model: *nsamples25000_res112_blurFalse_threshFalse_polyTrue*\n",
      "Time is: 2020-05-31 13:02:49.080364\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27a9c2051d9a4bd4b1b2598c3fa36eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 4.0 % of data, 25000 out of 643471 data points\n",
      "Data shape: (25000, 112, 112)\n",
      "Data size in RAM: 299.07 MB\n",
      "Data reshaped shape: (25000, 112, 112, 1)\n",
      "Train shape: (20000, 112, 112, 1), test shape: (5000, 112, 112, 1)\n",
      "Mse threshold: 0.02389924278110255\n",
      "Outliers found: 15\n",
      "*******************************\n",
      "Running model: *nsamples25000_res112_blurFalse_threshTrue_polyFalse*\n",
      "Time is: 2020-05-31 13:18:37.966908\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0230fa312ea4260be9c9f88401f5009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception, will use previous image instead. Error: issue with frame! /data/security_cam_detections_v2/Front-Parking/2020-01-22/23.44.56.334_9153465f_car.jpg\n",
      "\n",
      "Sampled 4.0 % of data, 25000 out of 643471 data points\n",
      "Data shape: (25000, 112, 112)\n",
      "Data size in RAM: 299.07 MB\n",
      "Data reshaped shape: (25000, 112, 112, 1)\n",
      "Train shape: (20000, 112, 112, 1), test shape: (5000, 112, 112, 1)\n",
      "Mse threshold: 0.10205888702720395\n",
      "Outliers found: 15\n",
      "*******************************\n",
      "Running model: *nsamples25000_res112_blurFalse_threshTrue_polyTrue*\n",
      "Time is: 2020-05-31 13:35:06.494246\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afdded5eb2f34086ac53d180f62a9b22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 4.0 % of data, 25000 out of 643471 data points\n",
      "Data shape: (25000, 112, 112)\n",
      "Data size in RAM: 299.07 MB\n",
      "Data reshaped shape: (25000, 112, 112, 1)\n",
      "Train shape: (20000, 112, 112, 1), test shape: (5000, 112, 112, 1)\n",
      "Mse threshold: 0.08668422760069365\n",
      "Outliers found: 15\n",
      "*******************************\n",
      "Running model: *nsamples25000_res112_blurTrue_threshFalse_polyFalse*\n",
      "Time is: 2020-05-31 13:50:57.585020\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc61ab8e8cb1452d8ab1ee2ca4d2ae77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 4.0 % of data, 25000 out of 643471 data points\n",
      "Data shape: (25000, 112, 112)\n",
      "Data size in RAM: 299.07 MB\n",
      "Data reshaped shape: (25000, 112, 112, 1)\n",
      "Train shape: (20000, 112, 112, 1), test shape: (5000, 112, 112, 1)\n",
      "Mse threshold: 0.016456498907878987\n",
      "Outliers found: 15\n",
      "*******************************\n",
      "Running model: *nsamples25000_res112_blurTrue_threshFalse_polyTrue*\n",
      "Time is: 2020-05-31 14:06:53.204942\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d357a2c801b4b10984a88db0176dcc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 4.0 % of data, 25000 out of 643471 data points\n",
      "Data shape: (25000, 112, 112)\n",
      "Data size in RAM: 299.07 MB\n",
      "Data reshaped shape: (25000, 112, 112, 1)\n",
      "Train shape: (20000, 112, 112, 1), test shape: (5000, 112, 112, 1)\n",
      "Mse threshold: 0.0137542036632075\n",
      "Outliers found: 15\n",
      "*******************************\n",
      "Running model: *nsamples25000_res112_blurTrue_threshTrue_polyFalse*\n",
      "Time is: 2020-05-31 14:22:44.539415\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "503c509b9b894905b9c6ae98711830b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 4.0 % of data, 25000 out of 643471 data points\n",
      "Data shape: (25000, 112, 112)\n",
      "Data size in RAM: 299.07 MB\n",
      "Data reshaped shape: (25000, 112, 112, 1)\n",
      "Train shape: (20000, 112, 112, 1), test shape: (5000, 112, 112, 1)\n",
      "Mse threshold: 0.09107830797135809\n",
      "Outliers found: 15\n",
      "*******************************\n",
      "Running model: *nsamples25000_res112_blurTrue_threshTrue_polyTrue*\n",
      "Time is: 2020-05-31 14:38:43.060296\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f4a8907acb4d53abd5f18511c5d2c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 4.0 % of data, 25000 out of 643471 data points\n",
      "Data shape: (25000, 112, 112)\n",
      "Data size in RAM: 299.07 MB\n",
      "Data reshaped shape: (25000, 112, 112, 1)\n",
      "Train shape: (20000, 112, 112, 1), test shape: (5000, 112, 112, 1)\n",
      "Mse threshold: 0.07718850255012483\n",
      "Outliers found: 15\n",
      "*******************************\n",
      "Running model: *nsamples50000_res28_blurFalse_threshFalse_polyFalse*\n",
      "Time is: 2020-05-31 14:54:27.750150\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d5c6073d2e4c89bac2547331161aa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 8.0 % of data, 50000 out of 643471 data points\n",
      "Data shape: (50000, 28, 28)\n",
      "Data size in RAM: 37.38 MB\n",
      "Data reshaped shape: (50000, 28, 28, 1)\n",
      "Train shape: (40000, 28, 28, 1), test shape: (10000, 28, 28, 1)\n",
      "Mse threshold: 0.0261735676527025\n",
      "Outliers found: 30\n",
      "*******************************\n",
      "Running model: *nsamples50000_res28_blurFalse_threshFalse_polyTrue*\n",
      "Time is: 2020-05-31 15:07:15.715850\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce07bd350f264dee809f4878505a35ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception, will use previous image instead. Error: issue with frame! /data/security_cam_detections_v2/Front-Parking/2020-02-08/23.33.41.278_955bc21c_person.jpg\n",
      "\n",
      "Sampled 8.0 % of data, 50000 out of 643471 data points\n",
      "Data shape: (50000, 28, 28)\n",
      "Data size in RAM: 37.38 MB\n",
      "Data reshaped shape: (50000, 28, 28, 1)\n",
      "Train shape: (40000, 28, 28, 1), test shape: (10000, 28, 28, 1)\n",
      "Mse threshold: 0.023497307827696247\n",
      "Outliers found: 30\n",
      "*******************************\n",
      "Running model: *nsamples50000_res28_blurFalse_threshTrue_polyFalse*\n",
      "Time is: 2020-05-31 15:22:12.337288\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b73105784c4d6191d72977998e0aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception, will use previous image instead. Error: issue with frame! /data/security_cam_detections_v2/Front-Parking/2020-02-08/23.33.41.278_955bc21c_person.jpg\n",
      "\n",
      "Sampled 8.0 % of data, 50000 out of 643471 data points\n",
      "Data shape: (50000, 28, 28)\n",
      "Data size in RAM: 37.38 MB\n",
      "Data reshaped shape: (50000, 28, 28, 1)\n",
      "Train shape: (40000, 28, 28, 1), test shape: (10000, 28, 28, 1)\n",
      "Mse threshold: 0.10536933574825535\n",
      "Outliers found: 30\n",
      "*******************************\n",
      "Running model: *nsamples50000_res28_blurFalse_threshTrue_polyTrue*\n",
      "Time is: 2020-05-31 15:37:01.767757\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be694ae3e9f94457b9ea2a271edc6e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 8.0 % of data, 50000 out of 643471 data points\n",
      "Data shape: (50000, 28, 28)\n",
      "Data size in RAM: 37.38 MB\n",
      "Data reshaped shape: (50000, 28, 28, 1)\n",
      "Train shape: (40000, 28, 28, 1), test shape: (10000, 28, 28, 1)\n",
      "Mse threshold: 0.08562995991855886\n",
      "Outliers found: 30\n",
      "*******************************\n",
      "Running model: *nsamples50000_res28_blurTrue_threshFalse_polyFalse*\n",
      "Time is: 2020-05-31 15:54:13.874685\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e43567004911412fadefb6ae2b3be470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 8.0 % of data, 50000 out of 643471 data points\n",
      "Data shape: (50000, 28, 28)\n",
      "Data size in RAM: 37.38 MB\n",
      "Data reshaped shape: (50000, 28, 28, 1)\n",
      "Train shape: (40000, 28, 28, 1), test shape: (10000, 28, 28, 1)\n",
      "Mse threshold: 0.005708286367356797\n",
      "Outliers found: 30\n",
      "*******************************\n",
      "Running model: *nsamples50000_res28_blurTrue_threshFalse_polyTrue*\n",
      "Time is: 2020-05-31 16:11:41.973137\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e5bb71dc58473fa4b63b20d965ab22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception, will use previous image instead. Error: issue with frame! /data/security_cam_detections_v2/Front-Parking/2020-01-25/23.32.10.835_4fa7e649_car.jpg\n",
      "\n",
      "Sampled 8.0 % of data, 50000 out of 643471 data points\n",
      "Data shape: (50000, 28, 28)\n",
      "Data size in RAM: 37.38 MB\n",
      "Data reshaped shape: (50000, 28, 28, 1)\n",
      "Train shape: (40000, 28, 28, 1), test shape: (10000, 28, 28, 1)\n",
      "Mse threshold: 0.004468954239971968\n",
      "Outliers found: 30\n",
      "*******************************\n",
      "Running model: *nsamples50000_res28_blurTrue_threshTrue_polyFalse*\n",
      "Time is: 2020-05-31 16:29:13.631750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1e79e173d0a4d9b8ed97a205a8ed150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception, will use previous image instead. Error: issue with frame! /data/security_cam_detections_v2/Front-Parking/2020-02-08/23.33.40.184_2c97eae7_person.jpg\n",
      "\n",
      "Sampled 8.0 % of data, 50000 out of 643471 data points\n",
      "Data shape: (50000, 28, 28)\n",
      "Data size in RAM: 37.38 MB\n",
      "Data reshaped shape: (50000, 28, 28, 1)\n",
      "Train shape: (40000, 28, 28, 1), test shape: (10000, 28, 28, 1)\n",
      "Mse threshold: 0.07784174690395611\n",
      "Outliers found: 30\n",
      "*******************************\n",
      "Running model: *nsamples50000_res28_blurTrue_threshTrue_polyTrue*\n",
      "Time is: 2020-05-31 16:46:36.673064\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e66395d5a184f8094aafe56db492e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception, will use previous image instead. Error: issue with frame! /data/security_cam_detections_v2/Front-Parking/2020-02-08/23.33.40.184_2c97eae7_person.jpg\n",
      "\n",
      "Sampled 8.0 % of data, 50000 out of 643471 data points\n",
      "Data shape: (50000, 28, 28)\n",
      "Data size in RAM: 37.38 MB\n",
      "Data reshaped shape: (50000, 28, 28, 1)\n",
      "Train shape: (40000, 28, 28, 1), test shape: (10000, 28, 28, 1)\n",
      "Mse threshold: 0.05955434598028689\n",
      "Outliers found: 30\n",
      "*******************************\n",
      "Running model: *nsamples50000_res56_blurFalse_threshFalse_polyFalse*\n",
      "Time is: 2020-05-31 17:03:56.095461\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ba1800b0cd47bf82bfb4d84e894517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 8.0 % of data, 50000 out of 643471 data points\n",
      "Data shape: (50000, 56, 56)\n",
      "Data size in RAM: 149.54 MB\n",
      "Data reshaped shape: (50000, 56, 56, 1)\n",
      "Train shape: (40000, 56, 56, 1), test shape: (10000, 56, 56, 1)\n",
      "Mse threshold: 0.027620661776512994\n",
      "Outliers found: 30\n",
      "*******************************\n",
      "Running model: *nsamples50000_res56_blurFalse_threshFalse_polyTrue*\n",
      "Time is: 2020-05-31 17:22:39.115226\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbda1f05a70c433c9a5c4d8ffc2b2cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 8.0 % of data, 50000 out of 643471 data points\n",
      "Data shape: (50000, 56, 56)\n",
      "Data size in RAM: 149.54 MB\n",
      "Data reshaped shape: (50000, 56, 56, 1)\n",
      "Train shape: (40000, 56, 56, 1), test shape: (10000, 56, 56, 1)\n",
      "Mse threshold: 0.024020547181367893\n",
      "Outliers found: 30\n",
      "*******************************\n",
      "Running model: *nsamples50000_res56_blurFalse_threshTrue_polyFalse*\n",
      "Time is: 2020-05-31 17:41:31.756034\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec86d239999487f816f41b1b511a39f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception, will use previous image instead. Error: issue with frame! /data/security_cam_detections_v2/Front-Parking/2020-02-01/23.46.24.903_33c7d43d_car.jpg\n",
      "\n",
      "Sampled 8.0 % of data, 50000 out of 643471 data points\n",
      "Data shape: (50000, 56, 56)\n",
      "Data size in RAM: 149.54 MB\n",
      "Data reshaped shape: (50000, 56, 56, 1)\n",
      "Train shape: (40000, 56, 56, 1), test shape: (10000, 56, 56, 1)\n",
      "Mse threshold: 0.10271805647015574\n",
      "Outliers found: 30\n",
      "*******************************\n",
      "Running model: *nsamples50000_res56_blurFalse_threshTrue_polyTrue*\n",
      "Time is: 2020-05-31 18:00:15.775903\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2674766ab25c43b1905869a1463927cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 8.0 % of data, 50000 out of 643471 data points\n",
      "Data shape: (50000, 56, 56)\n",
      "Data size in RAM: 149.54 MB\n",
      "Data reshaped shape: (50000, 56, 56, 1)\n",
      "Train shape: (40000, 56, 56, 1), test shape: (10000, 56, 56, 1)\n",
      "Mse threshold: 0.08550813137739907\n",
      "Outliers found: 30\n",
      "*******************************\n",
      "Running model: *nsamples50000_res56_blurTrue_threshFalse_polyFalse*\n",
      "Time is: 2020-05-31 18:19:11.910942\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff9a5574d61647e6be5086ab269b621e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception, will use previous image instead. Error: issue with frame! /data/security_cam_detections_v2/Front-Parking/2020-02-01/23.46.24.903_33c7d43d_car.jpg\n",
      "\n",
      "Sampled 8.0 % of data, 50000 out of 643471 data points\n",
      "Data shape: (50000, 56, 56)\n",
      "Data size in RAM: 149.54 MB\n",
      "Data reshaped shape: (50000, 56, 56, 1)\n",
      "Train shape: (40000, 56, 56, 1), test shape: (10000, 56, 56, 1)\n",
      "Mse threshold: 0.010222769326530408\n",
      "Outliers found: 30\n",
      "*******************************\n",
      "Running model: *nsamples50000_res56_blurTrue_threshFalse_polyTrue*\n",
      "Time is: 2020-05-31 18:37:29.201094\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c587b88d0941ac911fb8ccf93f20fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception, will use previous image instead. Error: issue with frame! /data/security_cam_detections_v2/Front-Parking/2020-01-22/23.44.56.334_9153465f_car.jpg\n",
      "\n",
      "Sampled 8.0 % of data, 50000 out of 643471 data points\n",
      "Data shape: (50000, 56, 56)\n",
      "Data size in RAM: 149.54 MB\n",
      "Data reshaped shape: (50000, 56, 56, 1)\n",
      "Train shape: (40000, 56, 56, 1), test shape: (10000, 56, 56, 1)\n",
      "Mse threshold: 0.008490424035117064\n",
      "Outliers found: 30\n",
      "*******************************\n",
      "Running model: *nsamples50000_res56_blurTrue_threshTrue_polyFalse*\n",
      "Time is: 2020-05-31 18:56:17.550541\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbf86b0023824dcf9c89bdc6e13518ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 8.0 % of data, 50000 out of 643471 data points\n",
      "Data shape: (50000, 56, 56)\n",
      "Data size in RAM: 149.54 MB\n",
      "Data reshaped shape: (50000, 56, 56, 1)\n",
      "Train shape: (40000, 56, 56, 1), test shape: (10000, 56, 56, 1)\n",
      "Mse threshold: 0.08238628645986332\n",
      "Outliers found: 30\n",
      "*******************************\n",
      "Running model: *nsamples50000_res56_blurTrue_threshTrue_polyTrue*\n",
      "Time is: 2020-05-31 19:14:33.398745\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7926a35d0db34fb687eb8dab0423f337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception, will use previous image instead. Error: issue with frame! /data/security_cam_detections_v2/Front-Parking/2020-01-25/23.32.10.990_4c062cda_car.jpg\n",
      "\n",
      "Sampled 8.0 % of data, 50000 out of 643471 data points\n",
      "Data shape: (50000, 56, 56)\n",
      "Data size in RAM: 149.54 MB\n",
      "Data reshaped shape: (50000, 56, 56, 1)\n",
      "Train shape: (40000, 56, 56, 1), test shape: (10000, 56, 56, 1)\n",
      "Mse threshold: 0.074545423604548\n",
      "Outliers found: 30\n",
      "*******************************\n",
      "Running model: *nsamples50000_res112_blurFalse_threshFalse_polyFalse*\n",
      "Time is: 2020-05-31 19:32:56.175589\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bf16d2f61b44e9b90e21c9366c5f69a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 8.0 % of data, 50000 out of 643471 data points\n",
      "Data shape: (50000, 112, 112)\n",
      "Data size in RAM: 598.14 MB\n",
      "Data reshaped shape: (50000, 112, 112, 1)\n",
      "Train shape: (40000, 112, 112, 1), test shape: (10000, 112, 112, 1)\n",
      "Mse threshold: 0.02547318059206039\n",
      "Outliers found: 30\n",
      "*******************************\n",
      "Running model: *nsamples50000_res112_blurFalse_threshFalse_polyTrue*\n",
      "Time is: 2020-05-31 20:04:48.639110\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5844cc33e38849718a34e7eb2a054aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 8.0 % of data, 50000 out of 643471 data points\n",
      "Data shape: (50000, 112, 112)\n",
      "Data size in RAM: 598.14 MB\n",
      "Data reshaped shape: (50000, 112, 112, 1)\n",
      "Train shape: (40000, 112, 112, 1), test shape: (10000, 112, 112, 1)\n",
      "Mse threshold: 0.02301630987040699\n",
      "Outliers found: 30\n",
      "*******************************\n",
      "Running model: *nsamples50000_res112_blurFalse_threshTrue_polyFalse*\n",
      "Time is: 2020-05-31 20:36:20.460344\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5382f49b67814ddaabc8913f3d0ae213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 8.0 % of data, 50000 out of 643471 data points\n",
      "Data shape: (50000, 112, 112)\n",
      "Data size in RAM: 598.14 MB\n",
      "Data reshaped shape: (50000, 112, 112, 1)\n",
      "Train shape: (40000, 112, 112, 1), test shape: (10000, 112, 112, 1)\n",
      "Mse threshold: 0.0997571442201735\n",
      "Outliers found: 30\n",
      "*******************************\n",
      "Running model: *nsamples50000_res112_blurFalse_threshTrue_polyTrue*\n",
      "Time is: 2020-05-31 21:08:08.720107\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b6df20aec8c4c72ab49a4c000495f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 8.0 % of data, 50000 out of 643471 data points\n",
      "Data shape: (50000, 112, 112)\n",
      "Data size in RAM: 598.14 MB\n",
      "Data reshaped shape: (50000, 112, 112, 1)\n",
      "Train shape: (40000, 112, 112, 1), test shape: (10000, 112, 112, 1)\n",
      "Mse threshold: 0.08334846816957002\n",
      "Outliers found: 30\n",
      "*******************************\n",
      "Running model: *nsamples50000_res112_blurTrue_threshFalse_polyFalse*\n",
      "Time is: 2020-05-31 21:39:47.673098\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bfd1b8e4ea54affa6387230aa1ad0bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception, will use previous image instead. Error: issue with frame! /data/security_cam_detections_v2/Front-Parking/2020-01-25/23.32.10.835_4fa7e649_car.jpg\n",
      "\n",
      "Sampled 8.0 % of data, 50000 out of 643471 data points\n",
      "Data shape: (50000, 112, 112)\n",
      "Data size in RAM: 598.14 MB\n",
      "Data reshaped shape: (50000, 112, 112, 1)\n",
      "Train shape: (40000, 112, 112, 1), test shape: (10000, 112, 112, 1)\n",
      "Mse threshold: 0.014380609516985828\n",
      "Outliers found: 30\n",
      "*******************************\n",
      "Running model: *nsamples50000_res112_blurTrue_threshFalse_polyTrue*\n",
      "Time is: 2020-05-31 22:11:32.423071\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "157bbc44b7a54f2ea89c74d866e1ded0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 8.0 % of data, 50000 out of 643471 data points\n",
      "Data shape: (50000, 112, 112)\n",
      "Data size in RAM: 598.14 MB\n",
      "Data reshaped shape: (50000, 112, 112, 1)\n",
      "Train shape: (40000, 112, 112, 1), test shape: (10000, 112, 112, 1)\n",
      "Mse threshold: 0.011778641268610973\n",
      "Outliers found: 30\n",
      "*******************************\n",
      "Running model: *nsamples50000_res112_blurTrue_threshTrue_polyFalse*\n",
      "Time is: 2020-05-31 22:43:20.379707\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "926d140efe7e4b1da2873066d7913f8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 8.0 % of data, 50000 out of 643471 data points\n",
      "Data shape: (50000, 112, 112)\n",
      "Data size in RAM: 598.14 MB\n",
      "Data reshaped shape: (50000, 112, 112, 1)\n",
      "Train shape: (40000, 112, 112, 1), test shape: (10000, 112, 112, 1)\n",
      "Mse threshold: 0.08484504243731507\n",
      "Outliers found: 30\n",
      "*******************************\n",
      "Running model: *nsamples50000_res112_blurTrue_threshTrue_polyTrue*\n",
      "Time is: 2020-05-31 23:15:07.601751\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3121350d52b4fca82d1ad1d004d9366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception, will use previous image instead. Error: issue with frame! /data/security_cam_detections_v2/Front-Parking/2020-01-22/23.44.56.510_02e043e7_car.jpg\n",
      "\n",
      "Sampled 8.0 % of data, 50000 out of 643471 data points\n",
      "Data shape: (50000, 112, 112)\n",
      "Data size in RAM: 598.14 MB\n",
      "Data reshaped shape: (50000, 112, 112, 1)\n",
      "Train shape: (40000, 112, 112, 1), test shape: (10000, 112, 112, 1)\n",
      "Mse threshold: 0.07764179100096258\n",
      "Outliers found: 30\n",
      "*******************************\n",
      "Done. Time is 2020-05-31 23:46:56.650149\n"
     ]
    }
   ],
   "source": [
    "# test parameters automatically and see what is classified as anomaly\n",
    "import itertools\n",
    "\n",
    "histories = {}\n",
    "real_params = ((10000, 25000, 50000), (28, 56, 112), (False, True), (False, True), (False, True))\n",
    "test_params = ((200, 300), (28, 56), (False, True), (False, True), (False, True))\n",
    "\n",
    "IMG_BASE_DIR = '/data/security_cam_detections_v2/Front-Parking'\n",
    "\n",
    "for n_samples, dim, is_blur, is_thresh, is_poly in itertools.product(*real_params):\n",
    "    model_name = f'nsamples{n_samples}_res{dim}_blur{is_blur}_thresh{is_thresh}_poly{is_poly}'\n",
    "    print(f'Running model: *{model_name}*')\n",
    "    print(f'Time is: {str(dt.now())}')\n",
    "    \n",
    "    dest_file_data = f'../Datasets/raw_images_processed/img__{model_name}.npy'\n",
    "    dest_file_filenames = f'../Datasets/raw_images_processed/filepaths__{model_name}.npy'\n",
    "\n",
    "    # how many rows to sample from dataframe\n",
    "    NUM_ROWS = n_samples\n",
    "\n",
    "    # resize images from 1080p to these dimensions\n",
    "    WIDTH, HEIGHT = dim, dim\n",
    "    \n",
    "    # if polyfill is used, use this percentage mask to cover the top area of image\n",
    "    POLY_VALUES = np.array([[0, 0], [1, 0], [1, 0.37], [0.5, 0.21], [0.25, 0.13], [0, 0.09]])  # poly-shape to mask\n",
    "    \n",
    "    # try:\n",
    "    #     # load files from disk, if don't exist, generate samples from the dataframe\n",
    "    #     im_data = np.load(dest_file_data)\n",
    "    #     im_filepaths = np.load(dest_file_filenames)\n",
    "    # except Exception as e:\n",
    "        # pre-allocate memory for the numpy array\n",
    "    im_data = np.zeros((NUM_ROWS, WIDTH, HEIGHT), dtype='uint8')\n",
    "    im_filepaths = []\n",
    "\n",
    "    # sample rows from the dataframe\n",
    "    samples = df.sample(NUM_ROWS)\n",
    "\n",
    "    # iterate through images and store in previously defined numpy array\n",
    "    im_processed_prev = None\n",
    "    im_path_prev = None\n",
    "    for i, (im_date, im_filename) in tqdm(enumerate(samples[['date', 'filename']].to_numpy())):\n",
    "        im_path = f'{IMG_BASE_DIR}/{im_date}/{im_filename}'\n",
    "        im_raw = cv2.imread(im_path)\n",
    "        try:\n",
    "            im_processed = process_frame(im_raw, (WIDTH, HEIGHT), is_gray=True, is_blur=is_blur,\n",
    "                                         is_thresh=is_thresh, is_polyfill=is_poly, poly_values=POLY_VALUES)\n",
    "        except Exception as e:\n",
    "            # if exception occurs when reading image, use previous image again\n",
    "            print('Exception, will use previous image instead.', str(e), im_path)\n",
    "            im_data[i] = im_processed_prev\n",
    "            im_filepaths.append(im_path_prev)\n",
    "            continue\n",
    "        im_processed_prev = im_processed.copy()\n",
    "        im_path_prev = im_path\n",
    "        im_data[i] = im_processed\n",
    "        im_filepaths.append(im_path)\n",
    "    im_filepaths = np.array(im_filepaths)\n",
    "\n",
    "    # save numpy arrays in the Datasets (efficient binary format)\n",
    "    np.save(dest_file_data, im_data)\n",
    "    np.save(dest_file_filenames, im_filepaths)\n",
    "\n",
    "    # print useful info\n",
    "    print(f\"Sampled {round(NUM_ROWS / df.shape[0], 2) * 100} % of data, {NUM_ROWS} out of {df.shape[0]} data points\")\n",
    "    print(f'Data shape: {im_data.shape}')\n",
    "    print(f'Data size in RAM: {round((im_data.size * im_data.itemsize) / 1024 / 1024, 2)} MB')\n",
    "    \n",
    "    # add a channel dimension to every image in the dataset, then scale\n",
    "    # the pixel intensities to the range [0, 1]\n",
    "    im_data = np.squeeze(im_data)\n",
    "    im_data = np.expand_dims(im_data, axis=-1)\n",
    "    im_data = im_data.astype(\"float32\") / 255.0\n",
    "    print(f'Data reshaped shape: {im_data.shape}')\n",
    "\n",
    "    # construct the training and testing split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(im_data, im_filepaths, test_size=0.2, random_state=42)\n",
    "    print(f'Train shape: {X_train.shape}, test shape: {X_test.shape}')\n",
    "    \n",
    "    # define model params\n",
    "    latent_dim=16\n",
    "    depth = 1\n",
    "    input_shape = (HEIGHT, WIDTH, depth)\n",
    "    chan_dim = -1\n",
    "\n",
    "    # CNN filters\n",
    "    filters=(32, 64)\n",
    "\n",
    "    # define the input to the encoder\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    # loop over the number of filters\n",
    "    for f in filters:\n",
    "        # apply a CONV => RELU => BN operation\n",
    "        x = Conv2D(f, (3, 3), strides=2, padding=\"same\")(x)\n",
    "        x = LeakyReLU(alpha=0.2)(x)\n",
    "        x = BatchNormalization(axis=chan_dim)(x)\n",
    "    # flatten the network and then construct our latent vector\n",
    "    volume_size = K.int_shape(x)\n",
    "    x = Flatten()(x)\n",
    "    latent = Dense(latent_dim)(x)\n",
    "    # build the encoder model\n",
    "    encoder = Model(inputs, latent, name=\"encoder\")\n",
    "\n",
    "    # start building the decoder model which will accept the\n",
    "    # output of the encoder as its inputs\n",
    "    latent_inputs = Input(shape=(latent_dim,))\n",
    "    x = Dense(np.prod(volume_size[1:]))(latent_inputs)\n",
    "    x = Reshape((volume_size[1], volume_size[2], volume_size[3]))(x)\n",
    "    # loop over our number of filters again, but this time in\n",
    "    # reverse order\n",
    "    for f in filters[::-1]:\n",
    "        # apply a CONV_TRANSPOSE => RELU => BN operation\n",
    "        x = Conv2DTranspose(f, (3, 3), strides=2, padding=\"same\")(x)\n",
    "        x = LeakyReLU(alpha=0.2)(x)\n",
    "        x = BatchNormalization(axis=chan_dim)(x)\n",
    "    # apply a single CONV_TRANSPOSE layer used to recover the\n",
    "    # original depth of the image\n",
    "    x = Conv2DTranspose(depth, (3, 3), padding=\"same\")(x)\n",
    "    outputs = Activation(\"sigmoid\")(x)\n",
    "    # build the decoder model\n",
    "    decoder = Model(latent_inputs, outputs, name=\"decoder\")\n",
    "\n",
    "    # our autoencoder is the encoder + decoder\n",
    "    autoencoder = Model(inputs, decoder(encoder(inputs)), name=\"autoencoder\")\n",
    "\n",
    "    # initialize the number of epochs to train for, initial learning rate,\n",
    "    # and batch size\n",
    "    EPOCHS = 50\n",
    "    INIT_LR = 1e-3\n",
    "    BS = 32\n",
    "\n",
    "    opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "    autoencoder.compile(loss=\"mse\", optimizer=opt)\n",
    "    \n",
    "    # train the convolutional autoencoder,\n",
    "    # note that the labels are actually the same\n",
    "    # as the training data\n",
    "    # save history data for later analysis\n",
    "    H = autoencoder.fit(X_train, X_train, validation_data=(X_test, X_test),\n",
    "                        epochs=EPOCHS, batch_size=BS, verbose=0)  # verbose to 0 to silence it\n",
    "    histories[model_name] = {'loss': H.history[\"loss\"], 'val_loss': H.history[\"val_loss\"], 'ts': str(dt.now())}\n",
    "    \n",
    "    # reconstruct data\n",
    "    reconstructed_data = autoencoder.predict(X_test)\n",
    "    \n",
    "    # calculate errors for test-set\n",
    "    errors = []\n",
    "    for (image, recon) in zip(X_test, reconstructed_data):\n",
    "        # compute the mean squared error between the ground-truth image\n",
    "        # and the reconstructed image, then add it to our list of errors\n",
    "        mse = np.mean((image - recon) ** 2)\n",
    "        errors.append(mse)\n",
    "    errors = np.array(errors)\n",
    "    \n",
    "    # compute the q-th quantile of the errors which serves as our\n",
    "    # threshold to identify anomalies -- any data point that our model\n",
    "    # reconstructed with > threshold error will be marked as an outlier\n",
    "    thresh = np.quantile(errors, 0.997)\n",
    "    idxs = np.where(np.array(errors) >= thresh)[0]\n",
    "    print(f\"Mse threshold: {thresh}\")\n",
    "    print(f\"Outliers found: {len(idxs)}\")\n",
    "    \n",
    "    # take a look at a few images with highest error\n",
    "    errors_df = pd.DataFrame({'mse': errors, 'y_test': y_test})\n",
    "    errors_df['is_anomaly'] = 'N'\n",
    "    errors_df.loc[errors_df['mse'] >= thresh, 'is_anomaly'] = 'Y'\n",
    "    errors_df = errors_df.sort_values('mse', ascending=False)\n",
    "    csv_filename = f'../Datasets/anomaly_results/{model_name}.csv'\n",
    "    errors_df.head(10).to_csv(csv_filename, index=False)\n",
    "    print('*******************************')\n",
    "\n",
    "now = str(dt.now())\n",
    "filename = f'../Datasets/histories/history_run_{now}.pickle'\n",
    "outfile = open(filename, 'wb')\n",
    "pickle.dump(histories, outfile)\n",
    "outfile.close()\n",
    "print(f'Done. Time is {now}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(histories.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Datasets/anomalies_labelled/yes/11.49.52.975_06f3ace1_dog.jpg\n",
      "(112, 112)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************\n"
     ]
    }
   ],
   "source": [
    "# test preprocessing\n",
    "WIDTH, HEIGHT = 112, 112\n",
    "POLY_VALUES = np.array([[0, 0], [1, 0], [1, 0.37], [0.5, 0.21], [0.25, 0.13], [0, 0.09]])  # poly-shape to mask\n",
    "im_dir_anom = '../Datasets/anomalies_labelled/yes'\n",
    "im_dir_normal = '../Datasets/anomalies_labelled/yes'\n",
    "for f in os.listdir(im_dir_anom)[2:]:\n",
    "    im_path = f'{im_dir_anom}/{f}'\n",
    "    print(im_path)\n",
    "    im_raw = cv2.imread(im_path)\n",
    "    im_processed = process_frame(im_raw, (WIDTH, HEIGHT), is_gray=True, is_blur=True, is_thresh=False,\n",
    "                                 is_polyfill=True, poly_values=POLY_VALUES, debug_poly=False)\n",
    "    #imshow(im_raw)\n",
    "    imshow(im_processed)\n",
    "    print('*************')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process images\n",
    "\n",
    "Take `NUM_ROWS` random samples from the DataFrame and follow the pipeline:\n",
    "- intialize numpy array (pre-allocate required memory)\n",
    "- take samples from dataframe\n",
    "- iterate through samples and for each data point:\n",
    "    - open image based on date and filename\n",
    "    - resize image\n",
    "    - convert to gray scale\n",
    "    - add to numpy data structure\n",
    "- print useful statistics about data shape and size\n",
    "- save numpy array on the disk in an efficient, binary format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define autoencoder architecture\n",
    "\n",
    "Inspired by [PyImageSearch blog](https://www.pyimagesearch.com/2020/03/02/anomaly-detection-with-keras-tensorflow-and-deep-learning/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
